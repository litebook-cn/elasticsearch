{"./":{"url":"./","title":"ElasticSearch 7 教程","keywords":"","body":" Elasticsearch是一个开源的分布式实时全文搜索和分析引擎。它用于单页应用程序项目。Elasticsearch是用Java开发的开源软件，被世界上许多大组织和公司使用。它是根据Apache许可证2.0版获得许可的。在这个简短的教程中，我们将解释Elasticsearch的基础及其特性。 受众群体 本教程是为希望通过简单易行的步骤学习Elasticsearch及其编程概念的软件专业人员设计的。它用适当的例子描述了弹性研究的组成部分。 先决条件 你应该对Java、JSON、搜索引擎和网络技术有一个基本的了解。由于与Elasticsearch的交互是通过RESTful应用编程接口实现的；因此，也建议您了解RESTful应用编程接口。 "},"basic-concepts.html":{"url":"basic-concepts.html","title":"基础概念","keywords":"","body":"基础概念 ElasticSearch是一个基于Apache Lucene的搜索服务器。它由谢伊·巴农(Shay Banon)开发，于2010年出版。它现在由ElasticSearch公司维护。截止到2019年6月19日，它的最新版本是7.1.1。 ElasticSearch是一个实时分布式开源全文搜索和分析引擎。它可以从RESTful网络服务接口访问，并使用无模式JSON (JavaScript对象符号)文档来存储数据。它建立在Java编程语言之上，使ElasticSearch能够在不同的平台上运行。它使用户能够以非常高的速度浏览非常大量的数据。 ElasticSearch的特点 ElasticSearch最多可扩展到千兆字节的结构化和非结构化数据。 ElasticSearch可以用来替代像MongoDB和RavenDB这样的文档存储。 ElasticSearch使用反规范化来提高搜索性能。 ElasticSearch(ElasticSearch)是流行的企业搜索引擎之一，目前正被维基百科、卫报、StackOverflow、GitHub等许多大组织使用。 ElasticSearch是开源的，在Apache许可版本2.0下可用。 ElasticSearch关键概念 Node（节点）:它指的是ElasticSearch的单个运行实例。单个物理和虚拟服务器可容纳多个节点，具体取决于其物理资源(如内存、存储和处理能力)的能力。 Cluster（集群）:它是一个或多个节点组成的集合。集群为整个数据提供跨节点的索引和搜索功能。 Index（索引）:包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的Document。比如说建立一个商品索引，里面可能就存放了所有的商品数据。 Type/Mapping（类型/映射):它是共享同一索引中一组公共字段的文档集合。例如，索引包含社交网络应用程序的数据，然后可以有特定类型的用户简档数据、另一种类型的消息数据和另一种类型的评论数据。 Document(文档):它是以JSON格式定义的特定方式的字段集合。每个文档都属于一个类型，并驻留在一个索引中。每个文档都有一个唯一的标识符，称为UID。 Shard(分片):单台机器无法存储大量数据，ElasticSearch可以将一个索引中的数据切分为多个Shard，分布在多台服务器上存储。有了Shard就可以横向扩展，存储更多数据，让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能。 Replicas(副本):服务器随时可能故障或宕机，此时Shard可能就会丢失，因此可以为每个Shard创建多个Replica副本。Replica可以在Shard故障时提供备用服务，保证数据不丢失，多个Replica还可以提升搜索操作的吞吐量和性能。 ElasticSearch的优势 ElasticSearch是在Java上开发的，这使得它在几乎每个平台上都是兼容的。 ElasticSearch是实时的，换句话说，一秒钟后添加的文档可以在这个引擎中搜索。 ElasticSearch是分布式的，这使得它易于在任何大组织中扩展和集成。 通过使用ElasticSearch中的网关概念，创建完整备份很容易。 与Apache Solr相比，在ElasticSearch中处理多用户非常容易。 ElasticSearch使用JSON对象作为响应，这使得用大量不同的编程语言调用ElasticSearch服务器成为可能。 ElasticSearch支持几乎所有文档类型，除了那些不支持文本呈现的。 ElasticSearch的缺点 ElasticSearch在处理请求和响应数据方面没有提供多语言支持(仅在JSON中可能)，这与Apache Solr不同，Apache Solr中可能有CSV、XML和JSON格式。 ElasticSearch也有分裂的问题，但在极少数情况下。 ElasticSearch与关系数据库系统的比较 在ElasticSearch中，索引是类型的集合，正如数据库是关系数据库管理系统中表的集合一样。每个表都是行的集合，就像每个映射都是JSON对象ElasticSearch的集合一样。 ElasticSearch RDBMS Index Database Shard Shard Mapping Table Field Field JSON Object Tuple "},"installation.html":{"url":"installation.html","title":"安装","keywords":"","body":"安装 本节向您ElasticSearch的安装步骤，ElasticSearch是基于java开发的软件，所以在安装ElasticSearch之前，我们需要先安装java。 安装java 访问https://www.oracle.com/technetwork/java/javase/downloads/index.html，下载java8或更新版本，本文以windows系统下安装java8为例。在打开的网页中找到“Java SE 8u211/Java SE 8u212”，点击它。 在新打开的页面中，先勾选“Accept License Agreement ”，然后根据你的操作系统选择x86或者x64，一般新电脑都是x64版本，点击右边的连接就可以下载安装包了。 下载后，双击安装即可，但是要记录一下java的安装路径，后面配置环境变量需要用到，本例使用C:\\java，如图。 安装完毕后，鼠标右键单击桌面上的“此电脑”图标，在弹出的菜单选择属性，桌面没有“此电脑”图标的话请百度相应的的文章。 进入系统属性界面后，点击左侧的“高级系统设置”，在弹出的窗口中点击右下角的“环境变量按钮”。 在环境变量界面，点击下方的“新建”按钮，新建名字为JAVA_HOME的变量，变量的值为java的安装路径，本文为C:\\java。 然后再新建classpath变量，变量的值为“.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar”，最前面的“.;”一定不能丢下。 最后找到PATH变量，双击它，把c:\\java添加进去即可，这样就可以在命令提示符中直接使用java命令了。 至此，Java就安装完毕了，打开命令提示符，输入java -version，正常就应该可以输出java的版本信息了。 安装ElasticSearch ElasticSearch的安装非常简单，访问https://www.elastic.co/cn/downloads/elasticsearch，下载最新的版本程序包（7.1.1），根据操作系统下载对应的版本，然后解压即可，在解压后的目录中找到bin\\elasticsearch.bat，双击它即可启动ElasticSearch，ElasticSearch的安装完毕。 安装Kibana Kibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作。我们可以用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互。用来测试ElasticSearch的那些api非常方便。 Kibana的安装也一样很简单，访问https://www.elastic.co/cn/downloads/kibana，根据操作系统下载最新版本的压缩包即可，解压后找到bin/kibana.bat双击执行即可启动Kibana，Kibana默认的端口为5601，打开浏览器访问http://localhost:5601，如果启动过程中没有任何错误的话就可以看到界面了。本教程中我们主要使用Kibana的开发工具，即http://localhost:5601/app/kibana#/dev_tools。 "},"populate.html":{"url":"populate.html","title":"准备工作","keywords":"","body":"准备工作 在本节中，我们将向ElasticSearch添加一些索引、映射和数据。这些数据将在本教程中解释的示例中使用。 我们先启动好ElasticSearch和Kibana，然后访问http://localhost:5601/app/kibana#/dev_tools，进入Kibana的开发工具界面，让我们一步一步做。 创建索引 在Kibana中执行如下命令。 PUT schools 响应内容 命令执行后，如果没有任何问题，会返回如下内容。 { \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"schools\" } 如果没有提示error，就意味着成功创建了索引 ，如图所示。 创建映射并添加数据 ElasticSearch将根据请求体中提供的数据自动创建映射，我们将使用其批量功能在该索引中添加多个JSON对象。 POST /schools/_bulk { \"index\": { \"_index\": \"schools\", \"_id\": \"1\" } } { \"name\": \"Central School\", \"description\": \"CBSE Affiliation\", \"street\": \"Nagan\", \"city\": \"paprola\", \"state\": \"HP\", \"zip\": \"176115\", \"location\": [ 31.8955385, 76.8380405 ], \"fees\": 2000, \"tags\": [ \"Senior Secondary\", \"beautiful campus\" ], \"rating\": \"3.5\" } { \"index\": { \"_index\": \"schools\", \"_id\": \"2\" } } { \"name\": \"Saint Paul School\", \"description\": \"ICSE Afiliation\", \"street\": \"Dawarka\", \"city\": \"Delhi\", \"state\": \"Delhi\", \"zip\": \"110075\", \"location\": [ 28.5733056, 77.0122136 ], \"fees\": 5000, \"tags\": [ \"Good Faculty\", \"Great Sports\" ], \"rating\": \"4.5\" } { \"index\": { \"_index\": \"schools\", \"_id\": \"3\" } } { \"name\": \"Crescent School\", \"description\": \"State Board Affiliation\", \"street\": \"Tonk Road\", \"city\": \"Jaipur\", \"state\": \"RJ\", \"zip\": \"176114\", \"location\": [ 26.8535922, 75.7923988 ], \"fees\": 2500, \"tags\": [ \"Well equipped labs\" ], \"rating\": \"4.5\" } 返回响应 { \"took\" : 273, \"errors\" : false, \"items\" : [ { \"index\" : { \"_index\" : \"schools\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1, \"status\" : 201 } }, { \"index\" : { \"_index\" : \"schools\", \"_type\" : \"_doc\", \"_id\" : \"2\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1, \"status\" : 201 } }, { \"index\" : { \"_index\" : \"schools\", \"_type\" : \"_doc\", \"_id\" : \"3\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 2, \"_primary_term\" : 1, \"status\" : 201 } } ] } 添加其他索引 POST schools_gov 返回响应 { \"acknowledged\" : true, \"shards_acknowledged\" : true, \"index\" : \"schools\" } (这意味着成功创建了索引) 添加其他数据 POST schools_gov/_bulk { \"index\":{ \"_index\":\"schools_gov\", \"_id\":\"1\" } } { \"name\":\"Model School\", \"description\":\"CBSE Affiliation\", \"street\":\"silk city\", \"city\":\"Hyderabad\", \"state\":\"AP\", \"zip\":\"500030\", \"location\":[17.3903703, 78.4752129], \"fees\":200, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3\" } { \"index\":{ \"_index\":\"schools_gov\", \"_id\":\"2\" } } { \"name\":\"Government School\", \"description\":\"State Board Affiliation\", \"street\":\"Hinjewadi\", \"city\":\"Pune\", \"state\":\"MH\", \"zip\":\"411057\", \"location\": [18.599752, 73.6821995], \"fees\":500, \"tags\":[\"Great Sports\"], \"rating\":\"4\" } 返回响应 { \"took\" : 293, \"errors\" : false, \"items\" : [ { \"index\" : { \"_index\" : \"schools_gov\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1, \"status\" : 201 } }, { \"index\" : { \"_index\" : \"schools_gov\", \"_type\" : \"_doc\", \"_id\" : \"2\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 1, \"_primary_term\" : 1, \"status\" : 201 } } ] } "},"conventions.html":{"url":"conventions.html","title":"API约定","keywords":"","body":"API约定 网络中的API是一组函数调用或其他编程指令，用于访问特定网络应用中的软件组件。例如，Facebook API帮助开发者通过从Facebook访问数据或其他功能来创建应用程序，它可以获取出生日期或更新用户状态。 ElasticSearch提供了REST风格API，可以通过URL访问JSON。ElasticSearch使用以下约定。 多重索引 API中的大多数操作，主要是针对一个或多个索引的搜索和其他操作。这有助于用户通过只执行一次查询请求，在多个地方或所有可用数据中进行搜索。许多不同的符号用于在多个索引中执行操作，我们将在这一部分讨论其中的一些。 逗号分隔符号 POST /index1,index2,index3/_search { \"query\":{ \"query_string\":{ \"query\":\"any_string\" } } } 响应 index1、index2、index3中包含any_string的JSON对象。 _all关键字 POST /_all/_search { \"query\":{ \"query_string\":{ \"query\":\"any_string\" } } } 响应 所有索引中包含any_string的JSON对象。 通配符( * , + , – ) POST /school*/_search { \"query\":{ \"query_string\":{ \"query\":\"CBSE\" } } } 响应 从所有school*开头的索引中找出包含“CBSE”的JSON对象。 或者，您也可以使用以下代码 POST /school*,-schools_gov /_search { \"query\":{ \"query_string\":{ \"query\":\"CBSE\" } } } 响应 从所有school*开头但是不包含schools_gov的索引中找出包含“CBSE”的JSON对象。 还有一些URL查询字符串参数： ignore_unavailabl：如果不存在URL中的一个或多个索引，将不会发生错误或停止操作。例如，schools索引存在，但book_shops不存在 POST /school*,book_shops/_search { \"query\":{ \"query_string\":{ \"query\":\"CBSE\" } } } 响应 { \"error\":{ \"root_cause\":[{ \"type\":\"index_not_found_exception\", \"reason\":\"no such index\", \"resource.type\":\"index_or_alias\", \"resource.id\":\"book_shops\", \"index\":\"book_shops\" }], \"type\":\"index_not_found_exception\", \"reason\":\"no such index\", \"resource.type\":\"index_or_alias\", \"resource.id\":\"book_shops\", \"index\":\"book_shops\" },\"status\":404 } 加上ignore_unavailable参数后的代码。 POST /school*,book_shops/_search?ignore_unavailable = true { \"query\":{ \"query_string\":{ \"query\":\"CBSE\" } } } 响应 无任何报错信息，忽略了不存在的索引，从所有school*开头的索引中找出包含“CBSE”的JSON对象。 allow_no_indices：如果没有指定通配符的索引，true值会防止引发错误。 举个例子，如果没有以schools_pri开头的索引。 POST /schools_pri*/_search?allow_no_indices = true { \"query\":{ \"match_all\":{} } } 响应 (无报错) { \"took\":1,\"timed_out\": false, \"_shards\":{\"total\":0, \"successful\":0, \"failed\":0}, \"hits\":{\"total\":0, \"max_score\":0.0, \"hits\":[]} } expand_wildcards：此参数决定通配符是否需要扩展为开放索引或封闭索引，或者两者兼有。该参数的值可以是open和close，也可以是none和all。 例子 POST /schools/_close 响应 {\"acknowledged\":true} 请看下面的代码。 POST /school*/_search?expand_wildcards = closed { \"query\":{ \"match_all\":{} } } 响应 { \"error\":{ \"root_cause\":[{ \"type\":\"index_closed_exception\", \"reason\":\"closed\", \"index\":\"schools\" }], \"type\":\"index_closed_exception\", \"reason\":\"closed\", \"index\":\"schools\" }, \"status\":403 } 索引名称中的日期数学支持 ElasticSearch提供了根据日期和时间搜索索引的功能。我们需要以特定的格式指定日期和时间。例如，accountdetail-2015.12.30，index将存储2015年12月30日的银行帐户详细信息。可以执行数学运算来获得特定日期或日期和时间范围的细节。 日期数学索引名称的格式： //_search static_name是表达式的一部分，它在每个日期的数学索引中保持不变，如帐户详细信息。date_math_expr包含像now-2d那样动态确定日期和时间的数学表达式。date_format包含日期以类似于年月日的索引形式写入的格式。如果今天的日期是2015年12月30日，则将返回accountdetail-2015.12.28。 表达式 解析为 accountdetail-2015.12.29 accountdetail-2015.11.30 accountdetail-2015.12 我们现在将看到ElasticSearch中的一些常见选项，这些选项可以用来以指定的格式获得响应。 漂亮的结果 我们可以获得格式良好的JSON对象，只需附加一个URL 查询参数，即pretty = true。 POST /schools/_search?pretty = true { \"query\":{ \"match_all\":{} } } 响应 …………………….. { \"_index\" : \"schools\", \"_type\" : \"school\", \"_id\" : \"1\", \"_score\" : 1.0, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\": [31.8955385, 76.8380405], \"fees\":2000, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.5\" } } …………………. 人类可读的输出 此选项可以将响应更改为人类可读的形式(如果human = true)或计算机可读的形式(如果human = false)。例如，如果human = true，那么 distance_kilometer = 20KM，如果human = false，那么distance_meter = 20000。 响应信息过滤 我们可以通过添加到field_path参数中来过滤响应信息，例如。 POST /schools/_search?filter_path = hits.total { \"query\":{ \"match_all\":{} } } 响应 {\"hits\":{\"total\":3}} "},"document-apis.html":{"url":"document-apis.html","title":"文档API","keywords":"","body":"文档API ElasticSearch提供单文档和多文档API，其中API调用分别针对单文档和多文档。 索引API 当使用特定映射对相应的索引发出请求时，它有助于在索引中添加或更新JSON文档。例如，下面的请求将把JSON对象添加到schools索引和school映射下。 POST /schools/school/4 { \"name\":\"City School\", \"description\":\"ICSE\", \"street\":\"West End\", \"city\":\"Meerut\", \"state\":\"UP\", \"zip\":\"250002\", \"location\":[28.9926174, 77.692485], \"fees\":3500, \"tags\":[\"fully computerized\"], \"rating\":\"4.5\" } 响应 { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"4\", \"_version\":1, \"_shards\":{\"total\":2, \"successful\":1,\"failed\":0}, \"created\":true } 自动创建索引 当请求将JSON对象添加到特定的索引时，如果该索引不存在，那么该应用编程接口会自动创建该索引以及该JSON对象的基础映射。可以通过将elasticsearch.yml文件中的下列参数值更改为false来禁用此功能。 action.auto_create_index:false index.mapper.dynamic:false 您还可以限制索引的自动创建，其中通过更改以下参数的值，只允许具有特定模式的索引名称 action.auto_create_index:+acc*,-bank* (其中+表示允许，而-表示不允许) 版本控制 ElasticSearch还提供版本控制功能。我们可以使用版本查询参数来指定文档的特定版本。例如， POST /schools/school/1?version = 1 { \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2200, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.3\" } 响应 { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_version\":2, \"_shards\":{\"total\":2, \"successful\":1,\"failed\":0}, \"created\":false } 有两种最重要的版本控制类型；内部版本控制是默认版本，从1开始，每次更新时递增，包括删除。版本号可以在外部设置。要启用此功能，我们需要将version_type设置为外部。 版本控制是一个实时过程，不受实时搜索操作的影响。 操作类型 操作类型用于强制创建操作，这有助于避免覆盖现有文档。 POST /tutorials/chapter/1?op_type = create { \"Text\":\"this is chapter one\" } 响应 { \"_index\":\"tutorials\", \"_type\":\"chapter\", \"_id\":\"1\", \"_version\":1, \"_shards\":{\"total\":2, \"successful\":1, \"failed\":0}, \"created\":true } 自动生成ID 当索引操作中未指定ID时，ElasticSearch会自动为该文档生成ID。 父子关系 您可以通过在URL查询参数中传递父文档的标识来定义任何文档的父文档。 POST /tutorials/article/1?parent = 1 { \"Text\":\"This is article 1 of chapter 1\" } 注意：如果在执行本示例时出现异常，请通过在索引中添加以下内容来重新创建索引。 { \"mappings\": { \"chapter\": {}, \"article\": { \"_parent\": { \"type\": \"chapter\" } } } } 超时 默认情况下，索引操作将在主分片上等待最多1分钟，超时后提示失败并响应错误。通过将值传递给timeout参数，可以显式更改此超时值。 POST /tutorials/chapter/2?timeout = 3m { \"Text\":\"This is chapter 2 waiting for primary shard for 3 minutes\" } Get API API通过对特定文档执行get请求来帮助获取JSON对象类型。例如： GET /schools/school/1 { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_version\":2, \"found\":true, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385,76.8380405], \"fees\":2200, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.3\" } } 此操作是实时的，不受索引刷新率的影响。 您也可以指定版本，然后ElasticSearch将只获取该版本的文档。 您还可以在请求中指定_all，以便ElasticSearch可以在每种类型中搜索该文档id，并返回第一个匹配的文档。 您也可以从特定文档的结果中指定所需的字段。 GET /schools/school/1?fields = name,fees 响应 …………………….. \"fields\":{ \"name\":[\"Central School\"], \"fees\":[2200] } …………………….. 您也可以通过在get请求中添加_source部分来获取结果中的源部分。 GET /schools/school/1/_source 响应 { \"name\":\"Central School\", \"description\":\"CBSE Afiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2200, \"tags\":[\"Senior Secondary\", \"beatiful campus\"], \"rating\":\"3.3\" } 您也可以在执行get操作之前通过将refresh参数设置为true来刷新碎片。 Delete API 您可以通过向ElasticSearch发送HTTP DELETE请求来删除特定的索引、映射或文档。例如， DELETE /schools/school/4 { \"found\":true, \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"4\", \"_version\":2, \"_shards\":{\"total\":2, \"successful\":1, \"failed\":0} } 可以指定文档的version来删除该特定版本。 可以指定路由参数从特定用户删除文档，如果文档不属于该特定用户，操作将失败。 在此操作中，您可以像获取应用程序接口一样指定refresh和timeout选项。 Update API 用于更新文档 POST /schools_gov/school/1/_update { \"script\":{ \"inline\": \"ctx._source.fees+ = inc\", \"params\":{ \"inc\": 500 } } } 响应 { \"_index\":\"schools_gov\", \"_type\":\"school\", \"_id\":\"1\", \"_version\":2, \"_shards\":{\"total\":2, \"successful\":1, \"failed\":0} } 注意：如果出现脚本异常，建议在elastcisearch.yml中添加以下行 script.inline: on script.indexed: on 您可以通过向更新的文档发送get请求来检查更新。 GET /schools_gov/school/1 Multi Get API 它拥有与GET API相同的功能，但是这个GET请求可以返回多个文档。我们使用文档数组来指定需要获取的所有文档的索引和id。 POST /_mget { \"docs\":[ { \"_index\": \"schools\", \"_id\": \"1\" }, { \"_index\":\"schools_gev\", \"_id\": \"2\" } ] } 响应 { \"docs\":[ { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_version\":1, \"found\":true, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Afiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385,76.8380405], \"fees\":2000, \"tags\":[\"Senior Secondary\", \"beatiful campus\"], \"rating\":\"3.5\" } }, { \"_index\":\"schools_gev\", \"_type\":\"school\", \"_id\":\"2\", \"error\":{ \"root_cause\":[{ \"type\":\"index_not_found_exception\", \"reason\":\"no such index\", \"index\":\"schools_gev\" }], \"type\":\"index_not_found_exception\", \"reason\":\"no such index\", \"index\":\"schools_gev\" } } ] } Bulk API 该API用于通过在一个请求中进行多个索引/删除操作来批量上传或删除JSON对象。我们需要添加“_bulk”关键字来调用这个应用程序接口。这个API的例子已经在填充ElasticSearch文章中执行过了。所有其他功能与GET API相同。 "},"search-apis.html":{"url":"search-apis.html","title":"搜索API","keywords":"","body":"搜索API 该API用于在 ElasticSearch中搜索内容。用户可以通过发送以查询字符串作为参数的get请求进行搜索，也可以在post请求的消息体中进行查询。所有的搜索APIS都支持多索引、多类型的（新版本的ES已经弱化了类型的概念，一个索引只支持一个类型）。 多索引 ElasticSearch允许我们搜索所有索引或某些特定索引中的文档。例如，如果我们需要搜索所有name包含central的文档。 GET /_search?q = name:central 响应 { \"took\":78, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":0.19178301, \"hits\":[{ \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":0.19178301, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2000, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.5\" } }] } } 或者，我们可以在schools、schools_gov索引中搜索相同的内容 GET /schools,schools_gov/_search?q = name:model 多类型 注意：新版本的ES已经弱化了类型的概念，一个索引只支持一个类型。 GET /schools/_search?q = tags:sports 响应 { \"took\":16, \"timed_out\":false, \"_shards\":{\"total\":5, \"successful\":5, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":0.5, \"hits\":[{ \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":0.5, \"_source\":{ \"name\":\"Saint Paul School\", \"description\":\"ICSE Afiliation\", \"street\":\"Dawarka\", \"city\":\"Delhi\", \"state\":\"Delhi\", \"zip\":\"110075\", \"location\":[28.5733056, 77.0122136], \"fees\":5000, \"tags\":[\"Good Faculty\", \"Great Sports\"], \"rating\":\"4.5\" } }] } } URI搜索 我们可以在URI中传递许多参数 Q：用于指定搜索的字符串 lenient：若将此参数设置为true，就可以忽略基于格式的错误。默认情况下，它为false。 fields:该参数帮助我们从选择性字段中获得响应。 sort:我们可以通过使用这个参数改变排序结果，这个参数允许的值是字段名:ASC/字段名:desc timeout:我们可以通过使用该参数来限制搜索时间，并且响应仅包含在指定时间内的命中。默认情况下，不指定timeout。 terminate_after:对于每个分片，我们可以将响应限制在指定数量的文档，一旦达到这个数量，查询将提前终止。默认情况下，不指定terminate_after。 from:从指定的索引开始返回. 默认为0. size:表示要返回的记录数. 默认为10. 请求体查询 我们也可以在请求体中使用DSL来指定查询条件，在前面的章节中已经给出了许多例子，例如： POST /schools/_search { \"query\":{ \"query_string\":{ \"query\":\"up\" } } } 响应 ………………………………………………. { \"_source\":{ \"name\":\"City School\", \"description\":\"ICSE\", \"street\":\"West End\", \"city\":\"Meerut\", \"state\":\"UP\", \"zip\":\"250002\", \"location\":[28.9926174, 77.692485], \"fees\":3500, \"tags\":[\"Well equipped labs\"],\"rating\":\"4.5\" } } ………………………………………………. "},"aggregations.html":{"url":"aggregations.html","title":"聚合","keywords":"","body":"聚合 该框架收集搜索查询选择的所有数据,该框架由许多构建块组成，有助于构建复杂的数据摘要,聚合的基本结构如下所示 \"aggregations\" : { \"\" : { \"\" : { } [,\"meta\" : { [] } ]? [,\"aggregations\" : { []+ } ]? } } 有不同类型的聚合，每种聚合都有自己的目的 度量聚合 这些聚合有助于根据聚合文档的字段值计算矩阵，有时一些值可以从脚本中生成。 数值矩阵可以像平均聚合一样是单值的，也可以像统计一样是多值的。 平均聚合 此聚合用于获取聚合文档中任何数字字段的平均值。例如， POST /schools/_search { \"aggs\":{ \"avg_fees\":{\"avg\":{\"field\":\"fees\"}} } } 响应 { \"took\":44, \"timed_out\":false, \"_shards\":{\"total\":5, \"successful\":5, \"failed\":0}, \"hits\":{ \"total\":3, \"max_score\":1.0, \"hits\":[ { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":1.0, \"_source\":{ \"name\":\"Saint Paul School\", \"description\":\"ICSE Affiliation\", \"street\":\"Dawarka\", \"city\":\"Delhi\", \"state\":\"Delhi\", \"zip\":\"110075\", \"location\":[28.5733056, 77.0122136], \"fees\":5000, \"tags\":[\"Good Faculty\", \"Great Sports\"], \"rating\":\"4.5\" } }, { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":1.0, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2200, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.3\" } }, { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"3\", \"_score\":1.0, \"_source\":{ \"name\":\"Crescent School\", \"description\":\"State Board Affiliation\", \"street\":\"Tonk Road\", \"city\":\"Jaipur\", \"state\":\"RJ\", \"zip\":\"176114\", \"location\":[26.8535922, 75.7923988], \"fees\":2500, \"tags\":[\"Well equipped labs\"], \"rating\":\"4.5\" } } ] }, \"aggregations\":{\"avg_fees\":{\"value\":3233.3333333333335}} } 如果该值不在一个或多个聚合文档中，默认情况下会被忽略。您可以在聚合中添加缺失字段，将缺失值视为默认值。 { \"aggs\":{ \"avg_fees\":{ \"avg\":{ \"field\":\"fees\" \"missing\":0 } } } } 基数聚合 这种聚合给出了特定字段的不同值的计数。例如， POST /schools*/_search { \"aggs\":{ \"distinct_name_count\":{\"cardinality\":{\"field\":\"name\"}} } } 响应 ……………………………………………… { \"name\":\"Government School\", \"description\":\"State Board Afiliation\", \"street\":\"Hinjewadi\", \"city\":\"Pune\", \"state\":\"MH\", \"zip\":\"411057\", \"location\":[18.599752, 73.6821995], \"fees\":500, \"tags\":[\"Great Sports\"], \"rating\":\"4\" }, { \"_index\":\"schools_gov\", \"_type\": \"school\", \"_id\":\"1\", \"_score\":1.0, \"_source\":{ \"name\":\"Model School\", \"description\":\"CBSE Affiliation\", \"street\":\"silk city\", \"city\":\"Hyderabad\", \"state\":\"AP\", \"zip\":\"500030\", \"location\":[17.3903703, 78.4752129], \"fees\":700, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3\" } }, \"aggregations\":{\"disticnt_name_count\":{\"value\":3}} ……………………………………………… 注意：基数的值是3，因为name中有三个不同的值：Government, School和Model。 扩展统计信息聚合 这种聚合会生成聚合文档中特定数值字段的所有统计信息。例如， POST /schools/_search { \"aggs\" : { \"fees_stats\" : { \"extended_stats\" : { \"field\" : \"fees\" } } } } 响应 ……………………………………………… { \"aggregations\":{ \"fees_stats\":{ \"count\":3, \"min\":2200.0, \"max\":5000.0, \"avg\":3233.3333333333335, \"sum\":9700.0, \"sum_of_squares\":3.609E7, \"variance\":1575555.555555556, \"std_deviation\":1255.2113589175156, \"std_deviation_bounds\":{ \"upper\":5743.756051168364, \"lower\":722.9106154983024 } } } } ……………………………………………… 最大聚合 此聚合会查找聚合文档中特定数值字段的最大值。例如， POST /schools*/_search { \"aggs\" : { \"max_fees\" : { \"max\" : { \"field\" : \"fees\" } } } } 响应 ……………………………………………… { aggregations\":{\"max_fees\":{\"value\":5000.0}} } ……………………………………………… 最小聚合 此聚合会查找聚合文档中特定数值字段的最小值。例如， POST /schools*/_search { \"aggs\" : { \"min_fees\" : { \"min\" : { \"field\" : \"fees\" } } } } 响应 ……………………………………………… \"aggregations\":{\"min_fees\":{\"value\":500.0}} ……………………………………………… 总和聚合 此聚合计算聚合文档中特定数字字段的和。例如， POST /schools*/_search { \"aggs\" : { \"total_fees\" : { \"sum\" : { \"field\" : \"fees\" } } } } 响应 ……………………………………………… \"aggregations\":{\"total_fees\":{\"value\":10900.0}} ……………………………………………… 还有一些其他度量聚合在特殊情况下使用，如地理边界聚合和地理质心聚合，用于地理定位。 Bucket聚合 这些聚合包含许多用于不同类型聚合的bucket，这些聚合有一个标准，该标准决定文档是否属于该bucket。Bucket聚合描述如下： 子聚集 此Bucket聚合生成一组文档，这些文档映射到父Bucket聚合。类型参数用于定义父索引。例如，我们有一个品牌及其不同的模型，然后模型类型将具有以下_parent字段 { \"model\" : { \"_parent\" : { \"type\" : \"brand\" } } } 还有许多其他特殊的bucket聚合，这些聚合在许多其他情况下很有用，它们是 Date Histogram Aggregation Date Range Aggregation Filter Aggregation Filters Aggregation Geo Distance Aggregation GeoHash grid Aggregation Global Aggregation Histogram Aggregation IPv4 Range Aggregation Missing Aggregation Nested Aggregation Range Aggregation Reverse nested Aggregation Sampler Aggregation Significant Terms Aggregation Terms Aggregation 聚合元数据 您可以使用元标签在请求时添加一些关于聚合的数据，并可以得到响应。例如， POST /school*/_search { \"aggs\" : { \"min_fees\" : { \"avg\" : { \"field\" : \"fees\" } , \"meta\" :{ \"dsc\" :\"Lowest Fees\" } } } } 响应 ……………………………………………… { \"aggregations\":{\"min_fees\":{\"meta\":{\"dsc\":\"Lowest Fees\"}, \"value\":2180.0}} } ……………………………………………… "},"index-api.html":{"url":"index-api.html","title":"索引API","keywords":"","body":"索引API 这些API负责管理索引的所有方面，如设置、别名、映射、索引模板。 创建索引 这个API用来创建索引，当用户将JSON对象传递给索引时，可以自动创建索引，也可以在此之前手动创建索引。要创建索引，您只需要发送一个带有settings、mappings和aliases的post请求，或者只发送一个不带正文的简单请求。例如， POST /colleges 响应 {\"acknowledged\":true} 或者，附带一些settings. POST /colleges { \"settings\" : { \"index\" : { \"number_of_shards\" : 5, \"number_of_replicas\" : 3 } } } 响应 {\"acknowledged\":true} 或者，附带一些mapping. POST /colleges { \"settings\" : { \"number_of_shards\" : 3 }, \"mappings\" : { \"type1\" : { \"_source\" : { \"enabled\" : false }, \"properties\" : { \"college_name\" : { \"type\" : \"string\" }, \"college type\" : {\"type\":\"string\"} } } } } 响应 {\"acknowledged\":true} 或者，附带一些alias。 POST /colleges { \"aliases\" : { \"alias_1\" : {}, \"alias_2\" : { \"filter\" : { \"term\" : {\"user\" : \"manu\" } }, \"routing\" : \"manu\" } } } 响应 {\"acknowledged\":true} 删除索引 该API用来删除任何索引。您只需要传递一个带有特定索引名称的删除请求。例如， DELETE /colleges 使用_all，*即可删除所有索引。 获取索引 这个API可以通过向一个或多个索引发送get请求，这将返回关于索引的信息。 GET /schools 响应 { \"schools\":{ \"aliases\":{}, \"mappings\":{ \"school\":{ \"properties\":{ \"city\":{\"type\":\"string\"}, \"description\":{\"type\":\"string\"}, \"fees\":{\"type\":\"long\"}, \"location\":{\"type\":\"double\"}, \"name\":{\"type\":\"string\"}, \"rating\":{\"type\":\"string\"}, \"state\":{\"type\":\"string\"}, \"street\":{\"type\":\"string\"}, \"tags\":{\"type\":\"string\"}, \"zip\":{\"type\":\"string\"} } } }, \"settings\":{ \"index\":{ \"creation_date\":\"1454409831535\", \"number_of_shards\":\"5\", \"number_of_replicas\":\"1\", \"uuid\":\"iKdjTtXQSMCW4xZMhpsOVA\", \"version\":{\"created\":\"2010199\"} } }, \"warmers\":{} } } 您可以使用_all或*获取所有的信息。 检查索引是否存在 向某个索引发送GET请求，就可以确定该索引是否存在。如果HTTP响应为200，则存在；如果是404，则不存在。 开启/关闭索引 通过在请求中添加_close或_open来请求索引，关闭或打开一个或多个索引非常容易。例如， POST /schools/_close 或者 POST /schools/_open 索引别名 这个API通过使用_aliases关键字帮助给索引赋予别名。单个别名可以映射到多个别名，别名不能与索引同名。例如， POST /_aliases { \"actions\" : [ { \"add\" : { \"index\" : \"schools\", \"alias\" : \"schools_pri\" } } ] } 响应 {\"acknowledged\":true} 然后， GET /schools_pri 响应 ……………………………………………… {\"schools\":{\"aliases\":{\"schools_pri\":{}},\"}} ……………………………………………… 索引设置 可以通过在网址末尾附加_settings关键字来获得索引的设置。例如， GET /schools/_settings 响应 { \"schools\":{ \"settings\":{ \"index\":{ \"creation_date\":\"1454409831535\", \"number_of_shards\":\"5\", \"number_of_replicas\":\"1\", \"uuid\":\"iKdjTtXQSMCW4xZMhpsOVA\", \"version\":{\"created\":\"2010199\"} } } } } 分词 该API帮助分析文本并发送带有偏移值和数据类型的token。例如， POST /_analyze { \"analyzer\" : \"standard\", \"text\" : \"you are reading this at tutorials point\" } 响应 { \"tokens\":[ {\"token\":\"you\", \"start_offset\":0, \"end_offset\":3, \"type\":\"\", \"position\":0}, {\"token\":\"are\", \"start_offset\":4, \"end_offset\":7, \"type\":\"\", \"position\":1}, {\"token\":\"reading\", \"start_offset\":8, \"end_offset\":15, \"type\":\"\", \"position\":2}, {\"token\":\"this\", \"start_offset\":16, \"end_offset\":20, \"type\":\"\", \"position\":3}, {\"token\":\"at\", \"start_offset\":21, \"end_offset\":23, \"type\":\"\", \"position\":4}, {\"token\":\"tutorials\", \"start_offset\":24, \"end_offset\":33, \"type\":\"\", \"position\":5}, {\"token\":\"point\", \"start_offset\":34, \"end_offset\":39, \"type\":\"\", \"position\":6} ] } 您也可以使用索引来分析文本，然后将根据与该索引相关联的分析器来分析文本。 索引模板 您还可以创建带有映射的索引模板，这些模板可以应用于新的索引。例如， POST /_template/template_a { \"template\" : \"tu*\", \"settings\" : { \"number_of_shards\" : 3 }, \"mappings\" : { \"chapter\" : { \"_source\" : { \"enabled\" : false } } } } 任何以“tu”开头的索引都将具有与template_a相同的设置。 索引统计 该API帮助您提取特定索引的统计信息。您只需要发送一个带有索引网址和_stats关键字的获取请求。 GET /schools/_stats 响应 ……………………………………………… {\"_shards\":{\"total\":10, \"successful\":5, \"failed\":0}, \"_all\":{\"primaries\":{\"docs\":{ \"count\":3, \"deleted\":0}}}, \"store\":{\"size_in_bytes\":16653, \"throttle_time_in_millis\":0}, ……………………………………………… Flush 此API用于清除索引内存中的数据并将其迁移到索引存储中，还可以清除内部事务日志。例如， GET /schools/_flush 响应 {\"_shards\":{\"total\":10, \"successful\":5, \"failed\":0}} 刷新 默认情况下，ElasticSearch会定时刷新，但是您可以使用_refresh显式刷新一个或多个索引。例如， GET /schools/_refresh 响应 {\"_shards\":{\"total\":10, \"successful\":5, \"failed\":0}} "},"cluster-api.html":{"url":"cluster-api.html","title":"集群API","keywords":"","body":"集群API 该API用于获取集群及其节点的信息，并对其进行更改。为了调用这个应用编程接口，我们需要指定节点名、地址或本地。例如， GET /_nodes/_local 响应 ……………………………………………… { \"cluster_name\":\"elasticsearch\", \"nodes\":{ \"Vy3KxqcHQdm4cIM22U1ewA\":{ \"name\":\"Red Guardian\", \"transport_address\":\"127.0.0.1:9300\", \"host\":\"127.0.0.1\", \"ip\":\"127.0.0.1\", \"version\":\"2.1.1\", \"build\":\"40e2c53\", \"http_address\":\"127.0.0.1:9200\", } } } ……………………………………………… 或者 Get /_nodes/127.0.0.1 响应 与上述示例相同。 群集健康 该API用于通过附加health关键字来获取集群的健康状态。例如， GET /_cluster/health 响应 { \"cluster_name\":\"elasticsearch\", \"status\":\"yellow\", \"timed_out\":false, \"number_of_nodes\":1, \"number_of_data_nodes\":1, \"active_primary_shards\":23, \"active_shards\":23, \"relocating_shards\":0, \"initializing_shards\":0, \"unassigned_shards\":23, \"delayed_unassigned_shards\":0, \"number_of_pending_tasks\":0, \"number_of_in_flight_fetch\":0, \"task_max_waiting_in_queue_millis\":0, \"active_shards_percent_as_number\":50.0 } 集群状态 用于通过在请求URL中附加state关键字来获取集群的状态信息。状态信息包含版本、主节点、其他节点、路由表、元数据和块。例如， GET /_cluster/state 10. Elasticsearch — Cluster APIs 响应 ……………………………………………… { \"cluster_name\":\"elasticsearch\", \"version\":27, \"state_uuid\":\"B3P7uHGKQUGsSsiX2rGYUQ\", \"master_node\":\"Vy3KxqcHQdm4cIM22U1ewA\", } ……………………………………………… 集群统计 这个API通过使用stats关键字来帮助检索关于集群的统计信息。该应用编程接口返回碎片号、存储大小、内存使用情况、节点数量、角色、操作系统和文件系统。例如， GET /_cluster/stats 响应 ……………………………………………… { \"timestamp\":1454496710020, \"cluster_name\":\"elasticsearch\", \"status\":\"yellow\", \"indices\":{ \"count\":5, \"shards\":{ \"total\":23, \"primaries\":23, \"replication\":0.0,\" } } } ……………………………………………… 挂起群集任务 此API用于监控任何集群中的挂起任务。任务类似于创建索引、更新映射、分配碎片、失败碎片等。例如， GET /_cluster/pending_tasks 集群重路由 此API用于将碎片从一个节点移动到另一个节点，或者取消任何分配或分配任何未分配的碎片。例如， POST /_cluster/reroute { \"commands\" : [ { \"move\" : { \"index\" : \"schools\", \"shard\" : 2, \"from_node\" : \"nodea\", \"to_node\" : \"nodeb\" } }, { \"allocate\" : { \"index\" : \"test\", \"shard\" : 1, \"node\" : \"nodec\" } } ] } 集群更新设置 此API允许您使用settings关键字更新集群的设置。有两种类型的设置—持久性设置(在重启时应用)和瞬态设置(在完全集群重启后不存在)。 节点统计 该API用于检索集群中一个或多个节点的统计信息。节点统计几乎与集群相同。例如， GET /_nodes/stats 响应 ……………………………………………… { \"cluster_name\":\"elasticsearch\", \"nodes\":{ \"Vy3KxqcHQdm4cIM22U1ewA\":{ \"timestamp\":1454497097572, \"name\":\"Red Guardian\", \"transport_address\":\"127.0.0.1:9300\", \"host\":\"127.0.0.1\", \"ip\":[\"127.0.0.1:9300\", } } } ……………………………………………… 节点热线程 该API帮助您检索集群中每个节点上当前热线程的信息。例如， GET /_nodes/hot_threads 响应 ……………………………………………… ::: {Red Guardian} {Vy3KxqcHQdm4cIM22U1ewA} {127.0.0.1}{127.0.0.1:9300}Hot threads at 2016-02-03T10:59:48.856Z, interval = 500ms, busiestThreads = 3, ignoreIdleThreads = true:0.0% (0s out of 500ms) cpu usage by thread 'Attach Listener' unique snapshot unique snapshot ……………………………………………… "},"query-dsl.html":{"url":"query-dsl.html","title":"DSL查询","keywords":"","body":"DSL查询 在ElasticSearch中，搜索是通过基于JSON的查询来实现的。查询由两种子句组成： 叶查询子句：这些子句是匹配、术语或范围，它们在特定字段中查找特定值。 复合查询子句：这些查询是叶查询子句和其他复合查询的组合，以提取所需的信息。 ElasticSearch支持大数据量查询。查询以query关键字开始，然后以JSON对象的形式包含条件和过滤器。不同类型的查询描述如下 Match All查询 这是最基本的查询；它返回所有内容，每个对象的得分为1.0。例如， POST /schools*/_search { \"query\":{ \"match_all\":{} } } 响应 { \"took\":1, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":5, \"max_score\":1.0, \"hits\":[ { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":1.0, \"_source\":{ \"name\":\"Saint Paul School\", \"description\":\"ICSE Affiliation\", \"street\":\"Dawarka\", \"city\":\"Delhi\", \"state\":\"Delhi\", \"zip\":\"110075\", \"location\":[28.5733056, 77.0122136], \"fees\":5000, \"tags\":[\"Good Faculty\", \"Great Sports\"], \"rating\":\"4.5\" } }, { \"_index\":\"schools_gov\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":1.0, \"_source\":{ \"name\":\"Government School\", \"description\":\"State Board Affiliation\", \"street\":\"Hinjewadi\", \"city\":\"Pune\", \"state\":\"MH\", \"zip\":\"411057\", \"location\":[18.599752, 73.6821995], \"fees\":500, \"tags\":[\"Great Sports\"], \"rating\":\"4\" } }, { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":1.0, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2200, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.3\" } }, { \"_index\":\"schools_gov\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":1.0, \"_source\":{ \"name\":\"Model School\", \"description\":\"CBSE Affiliation\", \"street\":\"silk city\", \"city\":\"Hyderabad\", \"state\":\"AP\", \"zip\":\"500030\", \"location\":[17.3903703, 78.4752129], \"fees\":700, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3\" } }, { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"3\", \"_score\":1.0, \"_source\":{ \"name\":\"Crescent School\", \"description\":\"State Board Affiliation\", \"street\":\"Tonk Road\", \"city\":\"Jaipur\", \"state\":\"RJ\", \"zip\":\"176114\", \"location\":[26.8535922, 75.7923988], \"fees\":2500, \"tags\":[\"Well equipped labs\"], \"rating\":\"4.5\" } } ] } } 全文检索 这些查询用于搜索全文，如章节或新闻文章。该查询根据与特定索引或文档相关联的分析器工作。在本节中，我们将讨论不同类型的全文检索。 Match查询 此查询将文本或短语与一个或多个字段的值相匹配。例如， POST /schools*/_search { \"query\":{ \"match\" : { \"city\":\"pune\" } } } 响应 { \"took\":1, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":0.30685282, \"hits\":[{ \"_index\":\"schools_gov\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":0.30685282, \"_source\":{ \"name\":\"Government School\", \"description\":\"State Board Afiliation\", \"street\":\"Hinjewadi\", \"city\":\"Pune\", \"state\":\"MH\", \"zip\":\"411057\", \"location\":[18.599752, 73.6821995], \"fees\":500, \"tags\":[\"Great Sports\"], \"rating\":\"4\" } }] } } multi_match查询 此查询将文本或短语与多个字段匹配。例如， POST /schools*/_search { \"query\":{ \"multi_match\" : { \"query\": \"hyderabad\", \"fields\": [ \"city\", \"state\" ] } } } 响应 { \"took\":16, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":0.09415865, \"hits\":[{ \"_index\":\"schools_gov\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":0.09415865, \"_source\":{ \"name\":\"Model School\", \" description\":\"CBSE Affiliation\", \"street\":\"silk city\", \"city\":\"Hyderabad\", \"state\":\"AP\", \"zip\":\"500030\", \"location\":[17.3903703, 78.4752129], \"fees\":700, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3\" } }] } } Query String查询 该查询使用查询解析器和query_string关键字。例如， POST /schools/_search { \"query\":{ \"query_string\":{ \"query\":\"good faculty\" } } } 响应 { \"took\":16, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":0.09492774, \"hits\":[{ \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":0.09492774, \"_source\":{ \"name\":\"Saint Paul School\", \"description\":\"ICSE Affiliation\", \"street\":\"Dawarka\", \"city\":\"Delhi\", \"state\":\"Delhi\", \"zip\":\"110075\", \"location\":[28.5733056, 77.0122136], \"fees\":5000, \"tags\":[\"Good Faculty\", \"Great Sports\"], \"rating\":\"4.5\" } }] } } Term查询 这些查询主要处理数字、日期等结构化数据。例如， POST /schools/_search { \"query\":{ \"term\":{\"zip\":\"176115\"} } } 响应 { \"took\":1, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":0.30685282, \"hits\":[{ \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":0.30685282, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2200, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.3\" } }] } } Range查询 该查询用于查找值在值范围之间的对象。为此，我们需要使用如下运算符 gte:大于等于 gt:大于 lte:小于等于 lt:小于 举个例子： POST /schools*/_search { \"query\":{ \"range\":{ \"rating\":{ \"gte\":3.5 } } } } 响应 { \"took\":31, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":3, \"max_score\":1.0, \"hits\":[ { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":1.0, \"_source\":{ \"name\":\"Saint Paul School\", \"description\":\"ICSE Affiliation\", \"street\":\"Dawarka\", \"city\":\"Delhi\", \"state\":\"Delhi\", \"zip\":\"110075\", \"location\":[28.5733056, 77.0122136], \"fees\":5000, \"tags\":[\"Good Faculty\", \"Great Sports\"], \"rating\":\"4.5\" } }, { \"_index\":\"schools_gov\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":1.0, \"_source\":{ \"name\":\"Government School\", \"description\":\"State Board Affiliation\", \"street\":\"Hinjewadi\", \"city\":\"Pune\", \"state\":\"MH\", \"zip\":\"411057\", \"location\":[18.599752, 73.6821995] \"fees\":500, \"tags\":[\"Great Sports\"], \"rating\":\"4\" } }, { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"3\", \"_score\":1.0, \"_source\":{ \"name\":\"Crescent School\", \"description\":\"State Board Affiliation\", \"street\":\"Tonk Road\", \"city\":\"Jaipur\", \"state\":\"RJ\", \"zip\":\"176114\", \"location\":[26.8535922, 75.7923988], \"fees\":2500, \"tags\":[\"Well equipped labs\"], \"rating\":\"4.5\" } } ] } } 其他类型的term级查询有： Exists查询：判断某个字段具有非空值。 Missing查询：与Exists查询相反，该查询搜索没有特定字段或字段值为空的对象。 Wildcard or regexp查询：该查询使用正则表达式来查找对象中的模式。 Type query查询：特定类型的文档。例如， POST /schools*/_search { \"query\":{ \"type\" : { \"value\" : \"school\" } } } 响应 指定索引中存在的所有school JSON对象。 复合查询 这些查询是通过使用布尔运算符(如and、or、not或for不同索引或具有函数调用等)彼此合并的不同查询的集合。例如， POST /schools*/_search { \"query\":{ \"filtered\":{ \"query\":{ \"match\":{ \"state\":\"UP\" } }, \"filter\":{ \"range\":{ \"rating\":{ \"gte\":4.0 } } } } } } 响应 { \"took\":16, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{\"total\":0, \"max_score\":null, \"hits\":[]} } Joining查询 这些查询用于包含多个映射或文档的情况。有两种类型的joining查询： 嵌套查询 这些查询处理嵌套映射(您将在下一章中了解更多)。 has_child和has_parent查询 这些查询用于检索在查询中匹配的文档的子文档或父文档。例如， POST /tutorials/_search { \"query\": { \"has_child\" : { \"type\" : \"article\", \"query\" : { \"match\" : { \"Text\" : \"This is article 1 of chapter 1\" } } } } } 响应 { \"took\":21, \"timed_out\":false, \"_shards\":{\"total\":5, \"successful\":5, \"failed\":0}, \"hits\":{ \"total\":1, \"max_score\":1.0, \"hits\":[{ \"_index\":\"tutorials\", \"_type\":\"chapter\", \"_id\":\"1\", \"_score\":1.0, \"_source\":{ \"Text\":\"this is chapter one\" } }] } } 地理位置查询 这些查询处理地理位置，这些查询有助于找到指定位置附近的学校或任何其他地点。您需要使用地理点数据类型。例如， POST /schools*/_search { \"query\":{ \"filtered\":{ \"filter\":{ \"geo_distance\":{ \"distance\":\"100km\", \"location\":[32.052098, 76.649294] } } } } } 响应 { \"took\":6, \"timed_out\":false, \"_shards\":{\"total\":10, \"successful\":10, \"failed\":0}, \"hits\":{ \"total\":2, \"max_score\":1.0, \"hits\":[ { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"2\", \"_score\":1.0, \"_source\":{ \"name\":\"Saint Paul School\", \"description\":\"ICSE Affiliation\", \"street\":\"Dawarka\", \"city\":\"Delhi\", \"state\":\"Delhi\", \"zip\":\"110075\", \"location\":[28.5733056, 77.0122136], \"fees\":5000, \"tags\":[\"Good Faculty\", \"Great Sports\"], \"rating\":\"4.5\" } }, { \"_index\":\"schools\", \"_type\":\"school\", \"_id\":\"1\", \"_score\":1.0, \"_source\":{ \"name\":\"Central School\", \"description\":\"CBSE Affiliation\", \"street\":\"Nagan\", \"city\":\"paprola\", \"state\":\"HP\", \"zip\":\"176115\", \"location\":[31.8955385, 76.8380405], \"fees\":2000, \"tags\":[\"Senior Secondary\", \"beautiful campus\"], \"rating\":\"3.5\" } } ] } } 注意，如果在执行上述示例时出现异常，请将以下mapping添加到您的索引中。 { \"mappings\":{ \"school\":{ \"_all\":{ \"enabled\":true }, \"properties\":{ \"location\":{ \"type\":\"geo_point\" } } } } } "},"mapping.html":{"url":"mapping.html","title":"映射","keywords":"","body":"映射 映射是存储在索引中的文档的描述，它定义了数据类型，如geo_point或string，以及文档和规则中字段的格式，以控制动态添加字段的映射。例如， POST /bankaccountdetails { \"mappings\":{ \"report\":{ \"_all\":{ \"enabled\":true }, \"properties\":{ \"name\":{ \"type\":\"string\"}, \"date\":{ \"type\":\"date\"}, \"balance\":{ \"type\":\"double\"}, \"liability\":{ \"type\":\"double\"} } } } } 响应 {\"acknowledged\":true} 字段数据类型 ElasticSearch支持文档中字段的多种不同数据类型。以下数据类型用于在ElasticSearch中存储字段 核心数据类型 这些是几乎所有系统都支持的基本数据类型，如integer, long, double, short, byte, double, float, string, date, Boolean和binary。 复杂数据类型 这些数据类型是核心数据类型的组合。像数组、JSON对象和嵌套数据类型。以下是嵌套数据类型的示例 POST /tabletennis/team/1 { \"group\" : \"players\", \"user\" : [ { \"first\" : \"dave\", \"last\" : \"jones\" }, { \"first\" : \"kevin\", \"last\" : \"morris\" } ] } 响应 { \"_index\":\"tabletennis\", \"_type\":\"team\", \"_id\":\"1\", \"_version\":1, \"_shards\":{\"total\":2, \"successful\":1, \"failed\":0}, \"created\":true } Geo数据类型 这些数据类型用于定义地理属性。例如，地理点用于定义经度和纬度，地理形状用于定义不同的几何形状，如矩形。 专用数据类型 这些数据类型用于特殊目的，如 IPv4 (“ip”)接受IP地址，完成数据类型用于支持自动完成建议和用于计算字符串中令牌数量的令牌计数。 映射类型 每个索引都有一个或多个映射类型，用于将索引的文档分成逻辑组。基于以下参数，映射可以彼此不同 元字段 这些字段提供关于映射和与其相关联的其他对象的信息。如_index、_type、_id和_source字段。 字段 不同的映射包含不同数量的字段和不同数据类型的字段。 动态映射 ElasticSearch为自动创建映射提供了一种用户友好的机制。用户可以将数据直接发布到任何未定义的映射中，ElasticSearch将自动创建映射，这称为动态映射。例如， POST /accountdetails/tansferreport { \"from_acc\":\"7056443341\", \"to_acc\":\"7032460534\", \"date\":\"11/1/2016\", \"amount\":10000 } 响应 { \"_index\":\"accountdetails\", \"_type\":\"tansferreport\", \"_id\":\"AVI3FeH0icjGpNBI4ake\", \"_version\":1, \"_shards\":{\"total\":2, \"successful\":1, \"failed\":0}, \"created\":true } 映射参数 映射参数定义了映射的结构、关于字段和存储的信息以及在搜索时如何分析映射的数据。这些是以下映射参数 analyzer boost coerce copy_to doc_values dynamic enabled fielddata geohash geohash_precision geohash_prefix format ignore_above ignore_malformed include_in_all index_options lat_lon index fields norms null_value position_increment_gap properties search_analyzer similarity store term_vector "},"analysis.html":{"url":"analysis.html","title":"分析","keywords":"","body":"分析 当在搜索操作期间处理查询时，分析模块分析任何索引中的内容.该模块由analyzer, tokenizer, tokenfilters和charfilters组成.如果未定义分析器，则默认情况下，内置analyzers, token, filters和tokenizers将在分析模块中注册.例如. POST /pictures { \"settings\": { \"analysis\": { \"analyzer\": { \"index_analyzer\": { \"tokenizer\": \"standard\", \"filter\": [ \"standard\", \"my_delimiter\", \"lowercase\", \"stop\", \"asciifolding\", \"porter_stem\" ] }, \"search_analyzer\": { \"tokenizer\": \"standard\", \"filter\": [ \"standard\", \"lowercase\", \"stop\", \"asciifolding\", \"porter_stem\" ] } }, \"filter\": { \"my_delimiter\": { \"type\": \"word_delimiter\", \"generate_word_parts\": true, \"catenate_words\": true, \"catenate_numbers\": true, \"catenate_all\": true, \"split_on_case_change\": true, \"preserve_original\": true, \"split_on_numerics\": true, \"stem_english_possessive\": true } } } } } 分析器 分析器由tokenizer和可选的token filter组成.这些分析器以逻辑名称注册在分析模块中，这些逻辑名称可以在映射定义中引用，也可以在一些API中引用.有如下几种默认分析仪 1.Standard analyzer (standard)：可以为此分析器设置stopwords和max_token_length设置.默认情况下，stopwords列表为空，最大令牌长度为255. 2.Simple analyzer (simple)：该分析器由小写标记器组成. 3.Whitespace analyzer (whitespace)：该分析器由空白标记器组成. 4.Stop analyzer (stop)：可以配置stopwords和stopwords_path.默认情况下，stopwords初始化为英文stopwords，stopwords_path包含一个包含stop words的文本文件的路径. 5.Keyword analyzer (keyword)：该分析器将整个流标记为单个标记.它可以用作邮政编码. 6.Pattern analyzer (pattern)：这个分析器主要处理正则表达式.像小写、模式、标志、停止字这样的设置可以在这个分析器中设置. 7.Language analyzer：这个分析器处理印地语、阿拉伯语、管道语等语言. 8.Snowball analyzer (snowball)：该分析器使用标准令牌化器，带有标准过滤器、小写过滤器、停止过滤器和雪球过滤器. 9.Custom analyzer (custom)：该分析器用于创建带有令牌化器的定制分析器，令牌化器带有可选的令牌过滤器和计费过滤器.可以在此分析器中配置令牌化器、过滤器、char_filter和position_increment_gap等设置. 令牌化器 令牌化器用于从ElasticSearch中的文本生成令牌.通过考虑空格或其他标点符号，文本可以被分解成记号.ElasticSearch有很多内置的标记器，可以在自定义分析器中使用. 1.Standard tokenizer (standard)：基于语法的令牌化器，可以为此令牌化器配置max_token_length. 2.Edge NGram tokenizer (edgeNGram)：为此令牌化器设置min_gram、max_gram、token_chars等设置. 3.Keyword tokenizer (keyword)：生成整个输入作为输出，并且可以为此设置缓冲区大小. 4.Letter tokenizer (letter)：捕获整个单词，直到遇到一个非字母. 5.Lowercase tokenizer (lowercase)：与Letter tokenizer的工作原理相同，但是在创建令牌后，它会将其更改为小写. 6.NGram Tokenizer (nGram)：为此令牌化器设置min_gram(默认值为1)、max_gram(默认值为2)和token_chars等设置. 7.Whitespace tokenizer (whitespace)：根据空白分隔文本. 8.Pattern tokenizer (pattern)：使用正则表达式作为令牌分隔符.可以为此令牌化器设置模式、标志和组设置. 9.UAX Email URL Tokenizer (uax_url_email)：与lie标准令牌化器相同，但它将电子邮件和网址视为单一令牌. 10.Path hierarchy tokenizer (path_hierarchy)：该令牌化器生成输入目录路径中存在的所有可能路径.此令牌化器可用的设置有分隔符(默认为/)、替换、缓冲区大小(默认为1024)、反转(默认为false)和跳过(默认为0). 11.Classic tokenizer (classic)：在基于语法的标记的基础上工作的.可以为此令牌化器设置max_token_length. 12.Thai tokenizer (thai)：该标记器用于泰语，并使用内置的泰语分段算法. 令牌过滤器 令牌过滤器从令牌化器接收输入，然后这些过滤器可以修改、删除或添加输入中的文本.ElasticSearch提供了大量内置令牌过滤器.其中大部分已经在前面的章节中解释过了. 字符过滤器 这些过滤器在标记器之前处理文本.字符过滤器查找特殊字符或html标记或指定的模式，然后要么删除它们，要么将其更改为适当的单词，如“&”和“删除html标记”.以下是同义词. txt中指定了同义词的分析器示例 { \"settings\":{ \"index\":{ \"analysis\":{ \"analyzer\":{ \"synonym\":{ \"tokenizer\":\"whitespace\", \"filter\":[\"synonym\"] } }, \"filter\":{ \"synonym\":{ \"type\":\"synonym\", \"synonyms_path\":\"synonym.txt\", \"ignore_case\":\"true\" } } } } } } "},"modules.html":{"url":"modules.html","title":"模块","keywords":"","body":"模块 ElasticSearch由许多模块组成，这些模块负责不同的功能。ElasticSearch模块有两种类型的设置： 静态设置-在开始使用ElasticSearch之前，需要在配置文件中配置这些设置。您需要更新群集中的所有关注节点，以反映这些设置的更改。 动态设置-这些设置可以在实时ElasticSearch中设置。 我们将在本章的以下部分讨论ElasticSearch的不同模块。 集群级路由和分片分配 群集级别设置决定将碎片分配给不同的节点，并重新分配碎片以重新平衡群集。以下是控制碎片分配的设置 集群级碎片分配 cluster.routing.allocation.enable：可选值all/primaries/new_primaries/none。 cluster.routing.allocation .node_concurrent_recoveries：数字值，默认2。限制并发碎片恢复的数量。 cluster.routing.allocation .node_initial_primaries_recoveries：数字值，默认4。限制并行初始主恢复的数量。 cluster.routing.allocation .same_shard.host：布尔值，默认false。限制同一物理节点中同一碎片的多个副本的分配。 indices.recovery.concurrent _streams：数字值，默认3。控制从对等碎片中碎片恢复时每个节点打开的网络流数量。 indices.recovery.concurrent _small_file_streams：数字值，默认2。控制碎片恢复时每个节点上大小小于5mb的小文件的打开流数量。 cluster.routing.rebalance.enable：可选值all/primaries/replicas/none。 cluster.routing.allocation .allow_rebalance：可选值always/indices_primaries _active/Indices_all_active。 cluster.routing.allocation.cluster _concurrent_rebalance：数字值，默认2。限制集群中并发碎片平衡的数量。 cluster.routing.allocation .balance.shard：浮点值，默认0.45f。定义分配给每个节点的碎片的权重因子。 cluster.routing.allocation .balance.index：浮点值，默认0.55f。定义在特定节点上分配的每个索引的碎片数比率。 cluster.routing.allocation .balance.threshold：非负数浮点值，默认1.0f。 执行操作的最小优化值。 基于磁盘的碎片分配 cluster.routing.allocation .disk.threshold_enabled：布尔值，默认true。 启用和禁用磁盘分配决策器。 cluster.routing.allocation .disk.watermark.low：字符值，默认85%。表示磁盘的最大使用量。 cluster.routing.allocation .disk.watermark.high：字符值，默认90%。分配时的最大使用量；如果在分配时达到这一点，ElasticSearch会将该碎片分配给另一个磁盘。 cluster.info.update.interval：字符值，默认30s。检查磁盘的间隔。 cluster.routing.allocation .disk.include_relocations：布尔值，默认true。决定在计算磁盘使用量时是否考虑当前分配的碎片。 集群发现 该模块帮助集群发现和维护其中所有节点的状态。在群集中添加或删除节点时，群集的状态会发生变化。群集名称设置用于创建不同群集之间的逻辑差异。有一些模块可以帮助您使用云供应商提供的API，它们包括：Azure发现、EC2发现、Google compute engine 发现、Zen发现。 网关 此模块维护整个群集重启期间的群集状态和碎片数据。以下是该模块的静态设置。 gateway.expected_ nodes：数字值，默认0。预计群集中用于恢复本地碎片的节点数。 gateway.expected_ master_nodes：数字值，默认0。开始恢复之前，群集中预期的主节点数。 gateway.expected_ data_nodes：数字值，默认0。开始恢复之前群集中预期的数据节点数。 gateway.recover_ after_time：字符值，默认5m。指定恢复过程等待开始的时间，而不考虑群集中加入的节点数量。 gateway.recover_ after_nodes gateway.recoverafter master_nodes gateway.recoverafter data_nodes HTTP 该模块管理HTTP协议客户端和ElasticSearch API之间的通信。可以通过将http.enabled的值更改为false来禁用此模块。以下是控制该模块的设置(在elasticsearch.yml中配置) http.port：设置ElasticSearch对外服务的端口，范围从9200到9300。 http.publish_port：该端口适用于http客户端，也适用于防火墙。 http.bind_host：http服务的主机地址。 http.publish_host：http客户端的主机地址。 http.max_content_length：http请求中内容的最大容量大小。其默认值为100mb。 http.max_initial_line_length：网址的最大大小，默认值为4kb。 http.max_header_size：最大http头大小，默认值为8kb。 http.compression：启用或禁用对压缩的支持，默认值为false。 http.pipelinig：启用或禁用超文本传输协议流水线。 http.pipelining.max_events：限制关闭一个HTTP请求之前要排队的事件数。 索引 该模块维护为每个索引全局设置的设置。以下设置主要与内存使用有关。 断路器 这用于防止操作导致故障。该设置主要限制JVM堆的大小。例如，indices.breaker.total.limit设置，默认为JVM堆的70%。 字段数据缓存 这主要用于在字段上聚合时。建议有足够的内存来分配它。可以使用indices.fielddata.cache.size设置来控制用于字段数据缓存的内存量。 节点查询缓存 该内存用于缓存查询结果。此缓存使用最近最少使用(LRU)驱逐策略。Indices.queries.cahce.size设置控制此缓存的内存大小。 索引缓冲区 该缓冲区将新创建的文档存储在索引中，并在缓冲区已满时刷新它们。设置类似indices.memory.index_buffer_size控制为该缓冲区分配的堆的数量。 碎片请求缓存 该缓存用于存储每个碎片的本地搜索数据。缓存可以在创建索引时启用，也可以通过发送网址参数来禁用。 Disable cache - ?request_cache = true Enable cache \"index.requests.cache.enable\": true 索引恢复 它在恢复过程中控制资源。以下是设置. indices.recovery.concurrent_streams:默认值3 indices.recovery.concurrent_small_file_streams:默认值2 indices.recovery.file_chunk_size:默认值512kb indices.recovery.translog_ops:默认值1000 indices.recovery.translog_size:默认值512kb indices.recovery.compress:默认值true indices.recovery.max_bytes_per_sec:默认值40mb TTL间隔 生存时间(TTL)间隔定义文档的时间，在此之后文档将被删除。以下是控制此过程的动态设置。 设置 默认值 indices.ttl.interval:默认值60s indices.ttl.bulk_size:默认值1000 节点 每个节点都可以选择是否是数据节点。您可以通过更改node.data设置来更改此属性。将该值设置为false将定义该节点不是数据节点。 "},"testing.html":{"url":"testing.html","title":"测试","keywords":"","body":"测试 ElasticSearch提供了一个jar文件，它可以添加到任何java集成开发环境中，并且可以用来测试与ElasticSearch相关的代码。通过使用ElasticSearch提供的框架，可以执行一系列测试。 单元测试 集成测试 随机测试 首先，您需要将ElasticSearch测试依赖项添加到您的程序中。为此，您可以使用maven，并可以在pom.xml中添加以下内容。 org.elasticsearch elasticsearch 2.1.0 EsSetup已被初始化以启动和停止弹性搜索节点，并创建索引。 EsSetup esSetup = new EsSetup(); esSetup.execute() 函数将创建索引，您需要指定设置、类型和数据。 单元测试 单元测试是使用JUnit和ElasticSearch测试框架进行的。节点和索引可以使用弹性搜索类创建，在测试方法中可以用来执行测试。ESTestCase和ESTokenStreamTestCase类用于此测试。 集成测试 集成测试在一个集群中使用多个节点。电子集成测试用例类用于此测试。有多种方法可以使准备测试用例的工作变得更加容易。 refresh()：集群中的所有索引都会刷新 ensureGreen()：确保绿色健康集群状态 ensureYellow()：确保黄色健康群集状态 createIndex(name)：使用传递给此方法的名称创建索引 flush()：集群中的所有索引都会被刷新 flushAndRefresh()：同时执行flush()和refresh() indexExists(name)：验证指定索引是否存在 clusterService()：返回集群服务java类 cluster()：返回测试集群类 测试集群方法 ensureAtLeastNumNodes(n)：确保群集中的最小节点数大于或等于指定数量。 ensureAtMostNumNodes(n)：确保群集中最多的节点数量小于或等于指定数量。 stopRandomNode()：停止群集中的随机节点 stopCurrentMasterNode()：停止主节点 stopRandomNonMaster()：停止群集中不是主节点的随机节点 buildNode()：创建新节点 startNode(settings)：启动新节点 nodeSettings()：覆盖此方法以更改节点设置 访问客户端 客户端用于访问群集中的不同节点并执行一些操作。方法用于获取随机客户端。ElasticSearch还提供了其他访问客户端的方法，这些方法可以使用esintegtESTscase . Internalcluster()方法来访问。 iterator()：这有助于您访问所有可用的客户端。 masterClient()：这将返回一个与主节点通信的客户端。 nonMasterClient()：这将返回一个不与主节点通信的客户端。 clientNodeClient()：这将返回当前在客户端节点上的客户端。 随机测试 这种测试用于用每一个可能的数据来测试用户的代码，以便将来任何类型的数据都不会失败。随机数据是执行该测试的最佳选择。 生成随机数据 在这个测试中，随机类由随机测试提供的实例进行实例化，并提供了许多获取不同类型数据的方法。 getRandom() 随机类的实例 randomBoolean() 随机Boolean randomByte() 随机byte randomShort() 随机short randomInt() 随机integer randomLong() 随机long randomFloat() 随机float randomDouble() 随机double randomLocale() 随机locale randomTimeZone() 随机time zone randomFrom() 随机element from array 断言 ElasticsearchAssertions和ElasticsearchGeoAssertions类包含断言，用于在测试时执行一些常见的检查。例如， SearchResponse seearchResponse = client().prepareSearch(); assertHitCount(searchResponse, 6); assertFirstHit(searchResponse, hasId(\"6\")); assertSearchHits(searchResponse, \"1\", \"2\", \"3\", \"4\",”5”,”6”); "},"java-initialization.html":{"url":"java-initialization.html","title":"JAVA实例：初始化","keywords":"","body":"JAVA实例：初始化 ElasticSearch提供了很多API供开发者调用，在过去的版本中，应用的比较广泛的是通过Transport端口调用相应的功能，但是新版本的ElasticSearch已经不推荐使用Transport端口，而是推荐使用REST的方式调用功能。本实例以Java REST Client为作为参考。 添加pom引用 org.elasticsearch elasticsearch 7.1.1 org.elasticsearch.client elasticsearch-rest-high-level-client 7.1.1 org.apache.logging.log4j log4j-api 2.8.2 org.apache.logging.log4j log4j-core 2.8.2 org.elasticsearch.client elasticsearch-rest-client 7.1.1 org.elasticsearch.client elasticsearch-rest-client-sniffer 7.1.1 Java High Level REST Client需要Java 1.8，并且依赖于Elasticsearch core项目。 初始化 RestHighLevelClient实例需要按如下方式构建: RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"localhost\", 9200, \"http\"), new HttpHost(\"localhost\", 9201, \"http\"))); 关闭客户端 RestHighLevelClient将根据提供的构建器在内部创建用于执行请求的客户端。该客户端维护一个连接池并启动一些线程，因此当您处理好请求时，您应该将其关闭以释放这些资源，改操作通过调用close()方法来完成: client.close(); "},"java-document-new-index-api.html":{"url":"java-document-new-index-api.html","title":"JAVA实例：添加新文档（indexRequest）","keywords":"","body":"JAVA实例：添加新文档（indexRequest） 添加新文档需要调用IndexRequest请求，可以直接传递json数据，如下: IndexRequest request = new IndexRequest(\"posts\"); //索引 request.id(\"1\"); //文档id String jsonString = \"{\" + \"\\\"user\\\":\\\"kimchy\\\",\" + \"\\\"postDate\\\":\\\"2013-01-30\\\",\" + \"\\\"message\\\":\\\"trying out Elasticsearch\\\"\" + \"}\"; request.source(jsonString, XContentType.JSON); //以字符串形式提供的文档源 也可以使用Map作为参数，如下 Map jsonMap = new HashMap<>(); jsonMap.put(\"user\", \"kimchy\"); jsonMap.put(\"postDate\", new Date()); jsonMap.put(\"message\", \"trying out Elasticsearch\"); IndexRequest indexRequest = new IndexRequest(\"posts\") .id(\"1\").source(jsonMap); //以Map形式提供的文档源，可自动转换为JSON格式 还可以使用XConttentBuilder构建内容。 XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject(); { builder.field(\"user\", \"kimchy\"); builder.timeField(\"postDate\", new Date()); builder.field(\"message\", \"trying out Elasticsearch\"); } builder.endObject(); IndexRequest indexRequest = new IndexRequest(\"posts\") .id(\"1\").source(builder); 直接用键值对对象构架数据。 IndexRequest indexRequest = new IndexRequest(\"posts\") .id(\"1\") .source(\"user\", \"kimchy\", \"postDate\", new Date(), \"message\", \"trying out Elasticsearch\"); 可选参数 以下是官方文档提供的可选参数。 request.routing(\"routing\"); //路由值 request.timeout(TimeValue.timeValueSeconds(1)); //设置超时 request.timeout(\"1s\"); ////以字符串形式设置超时时间 request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); //以WriteRequest.RefreshPolicy实例形式设置刷新策略 request.setRefreshPolicy(\"wait_for\");//以字符串形式刷新策略 request.version(2); //文档版本 request.versionType(VersionType.EXTERNAL); //文档类型 request.opType(DocWriteRequest.OpType.CREATE); //操作类型 request.opType(\"create\"); //操作类型 可选create或update request.setPipeline(\"pipeline\"); //索引文档之前要执行的摄取管道的名称 同步执行 当以下列方式执行IndexRequest时，客户端在继续执行代码之前，会等待返回索引响应: IndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的弹性响应异常，并将原始响应异常作为抑制异常添加到其中。 异步执行 我们也可以用异步方式执行IndexRequest，以便客户端可以直接返回。用户需要通过向异步索引方法传递请求和侦听器来指定如何处理响应或潜在故障: client.indexAsync(request, RequestOptions.DEFAULT, listener);// listener是执行完成时要使用的侦听器 异步方法不会阻塞并立即返回。一旦完成，如果执行成功完成，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同 一个典型的listener像下面这样： listener = new ActionListener() { @Override public void onResponse(IndexResponse indexResponse) {//执行成功的时候调用 } @Override public void onFailure(Exception e) {//执行失败的时候调用 } }; IndexResponse对象 返回的IndexResponse对象允许检索关于已执行操作的信息，如下所示: String index = indexResponse.getIndex(); String id = indexResponse.getId(); if (indexResponse.getResult() == DocWriteResponse.Result.CREATED) {//处理创建文档的情况 } else if (indexResponse.getResult() == DocWriteResponse.Result.UPDATED) {//处理文档更新的情况 } ReplicationResponse.ShardInfo shardInfo = indexResponse.getShardInfo(); if (shardInfo.getTotal() != shardInfo.getSuccessful()) {//处理成功的分片数少于总分片数时的情况 } if (shardInfo.getFailed() > 0) {//处理潜在的故障 for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) { String reason = failure.reason(); } } 如果存在版本冲突，将引发ElasticsearchException: IndexRequest request = new IndexRequest(\"posts\") .id(\"1\") .source(\"field\", \"value\") .setIfSeqNo(10L) .setIfPrimaryTerm(20); try { IndexResponse response = client.index(request, RequestOptions.DEFAULT); } catch(ElasticsearchException e) { if (e.status() == RestStatus.CONFLICT) { //引发的异常表明返回了版本冲突错误 } } 如果opType被设置为创建并且已经存在具有相同索引和id的文档，也会发生同样的情况: IndexRequest request = new IndexRequest(\"posts\") .id(\"1\") .source(\"field\", \"value\") .opType(DocWriteRequest.OpType.CREATE); try { IndexResponse response = client.index(request, RequestOptions.DEFAULT); } catch(ElasticsearchException e) { if (e.status() == RestStatus.CONFLICT) { //引发的异常表明返回了版本冲突错误 } } 文档参考地址：https://www.elastic.co/guide/en/elasticsearch/client/java-rest/7.1/java-rest-high-document-index.html "},"java-get-document-api.html":{"url":"java-get-document-api.html","title":"JAVA实例：获取文档","keywords":"","body":"JAVA实例：获取文档 GetRequest 要获取一个文档，需要使用GetRequest对象，GetRequest的调用如下: GetRequest getRequest = new GetRequest( \"posts\", //索引名称 \"1\"); //文档id 可选参数 request.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE); //禁用源检索，默认情况下启用 String[] includes = new String[]{\"message\", \"*Date\"}; String[] excludes = Strings.EMPTY_ARRAY; FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes); request.fetchSourceContext(fetchSourceContext); //为特定字段配置源包含 String[] includes = Strings.EMPTY_ARRAY; String[] excludes = new String[]{\"message\"}; FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes); request.fetchSourceContext(fetchSourceContext); //为特定字段配置源排除 request.storedFields(\"message\"); //配置特定存储字段的检索(要求字段在映射中单独存储) GetResponse getResponse = client.get(request, RequestOptions.DEFAULT); String message = getResponse.getField(\"message\").getValue(); //检索消息存储字段(要求该字段单独存储在映射中) request.routing(\"routing\"); //路由值 request.preference(\"preference\"); //偏好值 request.realtime(false); //将realtime标志设置为false request.refresh(true); //在检索文档之前执行刷新(默认为false) request.version(2); //版本 request.versionType(VersionType.EXTERNAL); //版本类型 同步执行 当以下列方式执行GetRequest时，客户端会在继续执行代码之前等待GetResponse返回: GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 执行GetRequest也可以异步方式完成，这样客户端就可以直接返回。用户需要通过向异步get方法传递请求和侦听器来指定如何处理响应或潜在故障: client.getAsync(request, RequestOptions.DEFAULT, listener); //要执行的GetRequest和执行完成时要使用的ActionListener 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 一个典型的listener如下： ActionListener listener = new ActionListener() { @Override public void onResponse(GetResponse getResponse) {//执行成功的时候调用 } @Override public void onFailure(Exception e) {//出错的时候调用 } } GetResponse对象 返回的GetResponse允许检索请求的文档及其元数据和最终存储的字段。 String index = getResponse.getIndex(); String id = getResponse.getId(); if (getResponse.isExists()) { long version = getResponse.getVersion(); String sourceAsString = getResponse.getSourceAsString(); //以字符串形式检索文档 Map sourceAsMap = getResponse.getSourceAsMap(); //以Map的形式检索文档 byte[] sourceAsBytes = getResponse.getSourceAsBytes(); //以byte[]形式检索文档 } else { } 处理找不到文档的情况。请注意，虽然返回的响应有404个状态代码，但返回的是有效的GetResponse，而不是引发的异常。这种响应不包含任何源文档，其isExists方法返回false。 当对不存在的索引执行get请求时，响应具有404状态代码，会引发一个ElasticsearchException，需要按如下方式处理: GetRequest request = new GetRequest(\"does_not_exist\", \"1\"); try { GetResponse getResponse = client.get(request, RequestOptions.DEFAULT); } catch (ElasticsearchException e) { if (e.status() == RestStatus.NOT_FOUND) { //处理因索引不存在而引发的异常 } } 如果请求了特定的文档版本，并且现有文档具有不同的版本号，则会引发版本冲突: try { GetRequest request = new GetRequest(\"posts\", \"1\").version(2); GetResponse getResponse = client.get(request, RequestOptions.DEFAULT); } catch (ElasticsearchException exception) { if (exception.status() == RestStatus.CONFLICT) { //引发的异常表明返回了版本冲突错误 } } "},"java-exists-api.html":{"url":"java-exists-api.html","title":"JAVA实例：检查文档是否存在","keywords":"","body":"JAVA实例：检查文档是否存在 Exists API 如果文档存在，现有应用编程接口返回true，否则返回false。 Exists Request 使用GetRequest，就像获取应用程序接口一样。支持它的所有可选参数。由于exists()只返回true或false，我们建议关闭提取源和任何存储字段，这样消耗资源会少一些: GetRequest getRequest = new GetRequest( \"posts\", //索引 \"1\"); //文档id getRequest.fetchSourceContext(new FetchSourceContext(false)); //禁用fetching _source. getRequest.storedFields(\"_none_\"); 同步执行 当以下列方式执行GetRequest时，客户端在继续执行代码之前，会等待返回布尔值: boolean exists = client.exists(getRequest, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 执行GetRequest也可以异步方式完成，这样客户端就可以直接返回。用户需要通过向异步exists方法传递请求和侦听器来指定如何处理响应或潜在故障: client.existsAsync(getRequest, RequestOptions.DEFAULT, listener); //要执行的GetRequest和执行完成时要使用的ActionListener 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 一个典型的listener如下： ActionListener listener = new ActionListener() { @Override public void onResponse(Boolean exists) {//执行成功的时候调用 } @Override public void onFailure(Exception e) {//出错的时候调用 } }; Source exists request exists请求的一个变体是existsSource方法，该方法具有对所讨论的文档是否存储了源的附加检查。如果索引的映射选择了删除对在文档中存储JSON源的支持，那么对于该索引中的文档，此方法将返回false。 "},"java-delete-api.html":{"url":"java-delete-api.html","title":"JAVA实例：删除文档","keywords":"","body":"JAVA实例：删除文档 DeleteRequest 想要删除一个文档，必须构建一个DeleteRquest，如下： DeleteRequest request = new DeleteRequest( \"posts\", //索引 \"1\"); //文档id 可选参数 DeleteRequest同样有一些可选参数： request.routing(\"routing\"); //路由值 request.timeout(TimeValue.timeValueMinutes(2)); //以TimeValue形式设置超时 request.timeout(\"2m\"); //以字符串形式设置超时 request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); //以WriteRequest.RefreshPolicy实例的形式设置刷新策略 request.setRefreshPolicy(\"wait_for\"); //以字符串的形式设置刷新策略 request.version(2); //版本 request.versionType(VersionType.EXTERNAL); //版本类型 同步执行 当以下列方式执行删除请求时，客户端在继续执行代码之前，会等待返回删除响应: DeleteResponse deleteResponse = client.delete( request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 也可以异步方式执行DeleteRequest，以便客户端可以直接返回而无需等待。用户需要通过向异步删除方法传递请求和侦听器来指定如何处理响应或潜在问题: client.deleteAsync(request, RequestOptions.DEFAULT, listener); //要执行的删除请求和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 一个典型的监听器如下： listener = new ActionListener() { @Override public void onResponse(DeleteResponse deleteResponse) { //执行成功时调用 } @Override public void onFailure(Exception e) { //执行失败时调用 } }; DeleteResponse 返回的DeleteResponse允许检索关于已执行操作的信息，如下所示: String index = deleteResponse.getIndex(); String id = deleteResponse.getId(); long version = deleteResponse.getVersion(); ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo(); if (shardInfo.getTotal() != shardInfo.getSuccessful()) { //处理成功分片数少于总分片数的情况 } if (shardInfo.getFailed() > 0) { for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) {//处理潜在的故障 String reason = failure.reason(); } } 还可以检查文档是否被找到: DeleteRequest request = new DeleteRequest(\"posts\", \"does_not_exist\"); DeleteResponse deleteResponse = client.delete( request, RequestOptions.DEFAULT); if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) { //如果找不到要删除的文档，执行一些操作 } 如果存在版本冲突，将引发弹性响应异常: try { DeleteResponse deleteResponse = client.delete( new DeleteRequest(\"posts\", \"1\").setIfSeqNo(100).setIfPrimaryTerm(2), RequestOptions.DEFAULT); } catch (ElasticsearchException exception) { if (exception.status() == RestStatus.CONFLICT) { //引发的异常表明返回了版本冲突错误 } } "},"java-update-api.html":{"url":"java-update-api.html","title":"JAVA实例：更新文档","keywords":"","body":"JAVA实例：更新文档 UpdateRequest UpdateRequest request = new UpdateRequest( \"posts\", //索引 \"1\"); //文档id Update API允许通过使用脚本或传递部分文档来更新现有文档。 用脚本更新 该脚本可以作为内嵌脚本提供: Map parameters = singletonMap(\"count\", 4); //作为对象映射提供的脚本参数 Script inline = new Script(ScriptType.INLINE, \"painless\", \"ctx._source.field += params.count\", parameters); //使用painless语言和前面的参数创建内嵌脚本 request.script(inline); //将脚本设置为更新请求 或者作为存储的脚本: Script stored = new Script( ScriptType.STORED, null, \"increment-field\", parameters); //引用painless语言中存储在名称增量字段下的脚本 request.script(stored); //在更新请求中设置脚本 用部分文档更新 对部分文档使用更新时，部分文档将与现有文档合并。 部分文档可以以不同的方式提供: UpdateRequest request = new UpdateRequest(\"posts\", \"1\"); String jsonString = \"{\" + \"\\\"updated\\\":\\\"2017-01-01\\\",\" + \"\\\"reason\\\":\\\"daily update\\\"\" + \"}\"; request.doc(jsonString, XContentType.JSON); //以JSON格式的字符串形式提供的部分文档源 Map jsonMap = new HashMap<>(); jsonMap.put(\"updated\", new Date()); jsonMap.put(\"reason\", \"daily update\"); UpdateRequest request = new UpdateRequest(\"posts\", \"1\") .doc(jsonMap); //作为Map提供的部分文档源会自动转换为JSON格式 XContentBuilder builder = XContentFactory.jsonBuilder(); builder.startObject(); { builder.timeField(\"updated\", new Date()); builder.field(\"reason\", \"daily update\"); } builder.endObject(); UpdateRequest request = new UpdateRequest(\"posts\", \"1\") .doc(builder); //作为XContentBuilder对象提供的部分文档源，弹性搜索内置帮助器，用于生成JSON内容 UpdateRequest request = new UpdateRequest(\"posts\", \"1\") .doc(\"updated\", new Date(), \"reason\", \"daily update\"); //作为键值对提供的部分文档源，转换为JSON格式 Upserts 如果文档尚不存在，可以使用upsert方法定义一些将作为新文档插入的内容: String jsonString = \"{\\\"created\\\":\\\"2017-01-01\\\"}\"; request.upsert(jsonString, XContentType.JSON); //以字符串形式提供的Upsert文档源 与部分文档更新类似，可以使用接受字符串、Map、XContentBuilder或键值对的方法来定义upsert文档的内容。 可选参数 request.routing(\"routing\"); //路由值 request.timeout(TimeValue.timeValueSeconds(1)); //设置超时 request.timeout(\"1s\"); ////以字符串形式设置超时时间 request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); //以WriteRequest.RefreshPolicy实例形式设置刷新策略 request.setRefreshPolicy(\"wait_for\");//以字符串形式刷新策略 request.retryOnConflict(3); //如果要更新的文档在更新操作的获取和索引阶段之间被另一个操作更改，重试更新操作的次数 request.fetchSource(true); //启用源检索，默认情况下禁用 String[] includes = new String[]{\"updated\", \"r*\"}; String[] excludes = Strings.EMPTY_ARRAY; request.fetchSource( new FetchSourceContext(true, includes, excludes)); //为特定字段配置源包含 String[] includes = Strings.EMPTY_ARRAY; String[] excludes = new String[]{\"updated\"}; request.fetchSource( new FetchSourceContext(true, includes, excludes)); //为特定字段配置源排除 request.setIfSeqNo(2L); //ifSeqNo request.setIfPrimaryTerm(1L); //ifPrimaryTerm request.detectNoop(false); //禁用noop检测 request.scriptedUpsert(true); //指出无论文档是否存在，脚本都必须运行，即如果文档不存在，脚本负责创建文档。 request.docAsUpsert(true); //指示如果部分文档尚不存在，则必须将其用作upsert文档。 request.waitForActiveShards(2); //设置在继续更新操作之前必须活动的碎片副本数量。 request.waitForActiveShards(ActiveShardCount.ALL); //ActiveShardCount的碎片副本数。可选值：ActiveShardCount.ALL, ActiveShardCount.ONE或者 ActiveShardCount.DEFAULT 同步执行 当以下列方式执行更新请求时，客户端在继续执行代码之前，会等待返回更新响应: UpdateResponse updateResponse = client.update( request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 执行更新请求也可以异步方式完成，以便客户端可以直接返回。用户需要通过向异步更新方法传递请求和侦听器来指定如何处理响应或潜在故障: client.updateAsync(request, RequestOptions.DEFAULT, listener); //要执行的更新请求和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功完成，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 典型的更新监听器如下所示: listener = new ActionListener() { @Override public void onResponse(UpdateResponse updateResponse) { //成功的时候调用 } @Override public void onFailure(Exception e) { //失败的时候调用 } }; Update Response 返回的更新响应允许检索关于已执行操作的信息，如下所示: String index = updateResponse.getIndex(); String id = updateResponse.getId(); long version = updateResponse.getVersion(); if (updateResponse.getResult() == DocWriteResponse.Result.CREATED) { //处理第一次创建文档的情况(upsert) } else if (updateResponse.getResult() == DocWriteResponse.Result.UPDATED) { //处理文档更新的情况 } else if (updateResponse.getResult() == DocWriteResponse.Result.DELETED) { //处理文档被删除的情况 } else if (updateResponse.getResult() == DocWriteResponse.Result.NOOP) { //处理文档不受更新影响的情况，即没有对文档执行任何操作(noop) } 当通过fetchSource方法在更新请求中启用源检索时，响应包含更新文档的源: GetResult result = updateResponse.getGetResult(); //以GetResult形式检索更新的文档 if (result.isExists()) { String sourceAsString = result.sourceAsString(); //以字符串形式检索更新文档的来源 Map sourceAsMap = result.sourceAsMap(); //以Map的形式检索更新文档的源 byte[] sourceAsBytes = result.source(); //以byte[]的形式检索更新文档的源 } else { //处理响应中不存在文档源的情况(默认情况下就是这种情况) } 也可以检查碎片故障: ReplicationResponse.ShardInfo shardInfo = updateResponse.getShardInfo(); if (shardInfo.getTotal() != shardInfo.getSuccessful()) { //处理成功碎片数少于总碎片数的情况 } if (shardInfo.getFailed() > 0) { for (ReplicationResponse.ShardInfo.Failure failure : shardInfo.getFailures()) {//处理潜在的故障 String reason = failure.reason(); } } 当对不存在的文档执行UpdateRequest时，响应有404个状态代码，会引发一个ElasticsearchException，需要如下处理: UpdateRequest request = new UpdateRequest(\"posts\", \"does_not_exist\") .doc(\"field\", \"value\"); try { UpdateResponse updateResponse = client.update( request, RequestOptions.DEFAULT); } catch (ElasticsearchException e) { if (e.status() == RestStatus.NOT_FOUND) { //处理由于文档不存在而引发的异常 } } 如果存在版本冲突，将引发ElasticsearchException: UpdateRequest request = new UpdateRequest(\"posts\", \"1\") .doc(\"field\", \"value\") .setIfSeqNo(101L) .setIfPrimaryTerm(200L); try { UpdateResponse updateResponse = client.update( request, RequestOptions.DEFAULT); } catch(ElasticsearchException e) { if (e.status() == RestStatus.CONFLICT) { //引发的异常表明返回了版本冲突错误。 } } "},"java-term-vectors-api.html":{"url":"java-term-vectors-api.html","title":"JAVA实例：术语向量(Term Vectors)API","keywords":"","body":"JAVA实例：术语向量(Term Vectors)API 术语向量API返回特定文档字段中术语的信息和统计信息。文档可以存储在索引中或者由用户人工提供。 TermVectorsRequest 一个TermVectorsRequest需要一个索引、一个类型和一个id来指定某个文档以及为其检索信息的字段。 TermVectorsRequest request = new TermVectorsRequest(\"authors\", \"1\"); request.setFields(\"user\"); 也可以为人工文档生成术语向量，即索引中不存在的文档: XContentBuilder docBuilder = XContentFactory.jsonBuilder(); docBuilder.startObject().field(\"user\", \"guest-user\").endObject(); TermVectorsRequest request = new TermVectorsRequest(\"authors\", docBuilder); 一个人工文档作为XContentBuilder对象提供，XContentBuilder对象是生成JSON内容的Elasticsearch内置帮助器。 可选参数 request.setFieldStatistics(false); //将字段统计设置为false(默认为true)以忽略文档统计信息。 request.setTermStatistics(true); //将术语统计设置为true(默认为false)，以显示总术语频率和文档频率。 request.setPositions(false); //将位置设置为false(默认为true)，以忽略位置输出。 request.setOffsets(false); //将偏移量设置为false(默认为true)，以忽略偏移量的输出。 request.setPayloads(false); //将有效载荷设置为false(默认为true)，以忽略有效载荷的输出。 Map filterSettings = new HashMap<>(); filterSettings.put(\"max_num_terms\", 3); filterSettings.put(\"min_term_freq\", 1); filterSettings.put(\"max_term_freq\", 10); filterSettings.put(\"min_doc_freq\", 1); filterSettings.put(\"max_doc_freq\", 100); filterSettings.put(\"min_word_length\", 1); filterSettings.put(\"max_word_length\", 10); request.setFilterSettings(filterSettings); //设置过滤器设置，根据tf-idf分数过滤可返回的术语。 Map perFieldAnalyzer = new HashMap<>(); perFieldAnalyzer.put(\"user\", \"keyword\"); request.setPerFieldAnalyzer(perFieldAnalyzer); //将perFieldAnalyzer设置为指定与该字段不同的分析仪。 request.setRealtime(false); //将实时设置为假(默认值为真)以接近实时地检索术语向量。 request.setRouting(\"routing\"); //设置路由参数 同步执行 当以下列方式执行术语请求时，客户端在继续执行代码之前，等待返回术语响应: TermVectorsResponse response = client.termvectors(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 也可以异步方式执行TermVectorsRequest，以便客户端可以直接返回。用户需要通过将请求和侦听器传递给异步术语向量方法来指定如何处理响应或潜在故障: client.termvectorsAsync(request, RequestOptions.DEFAULT, listener); //要执行的术语向量请求和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 术语向量的典型监听器如下所示: listener = new ActionListener() { @Override public void onResponse(TermVectorsResponse termVectorsResponse) { //成功的时候调用 } @Override public void onFailure(Exception e) { //失败的时候调用 } }; TermVectorsResponse String index = response.getIndex(); //文档的索引名称。 String type = response.getType(); //文档的类型名称。 String id = response.getId(); //文档的id。 boolean found = response.getFound(); //指示是否找到文档。 检查术语向量 如果术语向量响应包含非空的术语向量列表，则可以使用以下方法获得关于每个术语向量的信息: for (TermVectorsResponse.TermVector tv : response.getTermVectorsList()) { String fieldname = tv.getFieldName(); //当前字段的名称 int docCount = tv.getFieldStatistics().getDocCount(); //当前字段-文档计数的字段统计 long sumTotalTermFreq = tv.getFieldStatistics().getSumTotalTermFreq(); //当前字段的字段统计信息-总术语频率之和 long sumDocFreq = tv.getFieldStatistics().getSumDocFreq(); //当前字段的字段统计信息-文档频率的总和 if (tv.getTerms() != null) {当前字段的术语 List terms = tv.getTerms(); // for (TermVectorsResponse.TermVector.Term term : terms) { String termStr = term.getTerm(); //术语的名称 int termFreq = term.getTermFreq(); //术语的术语频率 int docFreq = term.getDocFreq(); //记录术语的频率 long totalTermFreq = term.getTotalTermFreq(); //术语的总术语频率 float score = term.getScore(); //分数 if (term.getTokens() != null) { List tokens = term.getTokens(); //该术语的令牌 for (TermVectorsResponse.TermVector.Token token : tokens) { int position = token.getPosition(); //令牌的位置 int startOffset = token.getStartOffset(); //令牌的起始偏移量 int endOffset = token.getEndOffset(); //令牌的结束偏移量 String payload = token.getPayload(); //令牌的有效负载 } } } } } "},"java-bulk-api.html":{"url":"java-bulk-api.html","title":"JAVA实例：Bulk API","keywords":"","body":"JAVA实例：Bulk API Java高级REST客户端提供大容量处理器来帮助处理大容量请求。 BulkRequest BulkRequest可用于使用单个请求执行多个索引、更新和/或删除操作。 它需要将至少一个操作添加到批量请求中: BulkRequest request = new BulkRequest(); //创建BulkRequest request.add(new IndexRequest(\"posts\").id(\"1\") .source(XContentType.JSON,\"field\", \"foo\"));//将第一个索引请求添加到批量请求中 request.add(new IndexRequest(\"posts\").id(\"2\") .source(XContentType.JSON,\"field\", \"bar\"));//添加第二个索引请求 request.add(new IndexRequest(\"posts\").id(\"3\") .source(XContentType.JSON,\"field\", \"baz\"));//添加第三个索引请求 警告 Bulk API只支持JSON或SMILE中编码的文档。以任何其他格式提供文档都将导致错误。 不同的操作类型可以添加到同一个批量请求中: BulkRequest request = new BulkRequest(); request.add(new DeleteRequest(\"posts\", \"3\")); //向批量请求添加删除请求 request.add(new UpdateRequest(\"posts\", \"2\") .doc(XContentType.JSON,\"other\", \"test\"));//向批量请求添加更新请求。 request.add(new IndexRequest(\"posts\").id(\"4\") .source(XContentType.JSON,\"field\", \"baz\"));//使用SMILE格式添加索引请求 可选参数 request.timeout(TimeValue.timeValueMinutes(2)); //设置超时时间 request.timeout(\"2m\"); //设置超时时间 request.setRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL); //WriteRequest.RefreshPolicy实例形式设置刷新策略 request.setRefreshPolicy(\"wait_for\"); //字符串形式设置刷新策略 request.waitForActiveShards(2); //设置在继续索引/更新/删除操作之前必须活动的碎片副本的数量。 request.waitForActiveShards(ActiveShardCount.ALL); //作为动态硬装载提供的碎片副本数，可选：ActiveShardCount.ALL, ActiveShardCount.ONE或 ActiveShardCount.DEFAULT request.pipeline(\"pipelineId\"); //用于所有子请求的全局管道标识 request.routing(\"routingId\"); //用于全局路由所有子请求 BulkRequest defaulted = new BulkRequest(\"posts\"); //具有全局索引的批量请求，用于所有子请求，除非在子请求上被重写。此参数为@Nullable，只能在批量请求创建期间设置。 同步执行 当以下列方式执行批量请求时，客户端在继续执行代码之前，会等待返回批量响应: BulkResponse bulkResponse = client.bulk(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 也可以异步方式执行BulkRequest，这样客户端就可以直接返回。用户需要通过将请求和侦听器传递给异步大容量方法来指定如何处理响应或潜在故障: client.bulkAsync(request, RequestOptions.DEFAULT, listener); //要执行的批量请求和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 一个典型的批量监听程序如下: ActionListener listener = new ActionListener() { @Override public void onResponse(BulkResponse bulkResponse) { //成功的时候调用 } @Override public void onFailure(Exception e) { //出错的时候调用 } }; BulkResponse 返回的BulkResponse包含有关已执行操作的信息，并允许迭代每个结果，如下所示: for (BulkItemResponse bulkItemResponse : bulkResponse) { //迭代所有操作的结果 DocWriteResponse itemResponse = bulkItemResponse.getResponse(); //检索操作的响应(成功与否)，可以是索引响应、更新响应或删除响应，它们都可以被视为DocWriteResponse实例 switch (bulkItemResponse.getOpType()) { case INDEX: //处理索引操作的响应 case CREATE: IndexResponse indexResponse = (IndexResponse) itemResponse; break; case UPDATE: //处理更新操作的响应 UpdateResponse updateResponse = (UpdateResponse) itemResponse; break; case DELETE: //处理删除操作的响应 DeleteResponse deleteResponse = (DeleteResponse) itemResponse; } } 批量响应提供了一种快速检查一个或多个操作是否失败的方法: if (bulkResponse.hasFailures()) { // 如果至少有一个操作失败，此方法返回true } 在这种情况下，有必要迭代所有操作结果，以检查操作是否失败，如果失败，则检索相应的失败: for (BulkItemResponse bulkItemResponse : bulkResponse) { if (bulkItemResponse.isFailed()) { //指示给定操作是否失败 BulkItemResponse.Failure failure = bulkItemResponse.getFailure(); //检索失败操作的失败 } } 批量处理器 批量处理器通过提供一个实用程序类简化了Bulk API的使用，该类允许索引/更新/删除操作在添加到处理器时透明地执行。 为了执行请求，批量处理器需要以下组件: RestHighLevelClient 该客户端用于执行批量请求并检索BulkResponse BulkProcessor.Listener 每次批量请求执行前后或批量请求失败时，都会调用该侦听器 那么批量处理器. builder方法可以用来构建一个新的批量处理器: BulkProcessor.Listener listener = new BulkProcessor.Listener() { //创建BulkProcessor.Listener @Override public void beforeBulk(long executionId, BulkRequest request) { //每次执行BulkRequest之前都会调用此方法 } @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) { //每次执行BulkRequest后都会调用此方法 } @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) { //当批量请求失败时调用此方法 } }; BulkProcessor.Builder 提供了配置批量处理器如何处理请求执行的方法: BulkProcessor bulkProcessor = BulkProcessor.builder( (request, bulkListener) -> client.bulkAsync(request, RequestOptions.DEFAULT, bulkListener), listener).build(); //通过从BulkProcessor.Builder调用build()方法来创建BulkProcessor。resthighleveloclient . BulkAsync()方法将用于在机罩下执行BulkRequest。 BulkProcessor.Builder 供了配置批量处理器如何处理请求执行的方法: BulkProcessor.Builder builder = BulkProcessor.builder( (request, bulkListener) -> client.bulkAsync(request, RequestOptions.DEFAULT, bulkListener), listener); builder.setBulkActions(500); //根据当前添加的操作数设置刷新新批量请求的时间(默认值为1000，-1禁用) builder.setBulkSize(new ByteSizeValue(1L, ByteSizeUnit.MB)); //根据当前添加的操作大小设置刷新新批量请求的时间(默认为5Mb，-1禁用) builder.setConcurrentRequests(0); //设置允许执行的并发请求数(默认为1，0仅允许执行单个请求) builder.setFlushInterval(TimeValue.timeValueSeconds(10L)); //设置一个刷新间隔，如果间隔过去，刷新任何待处理的批量请求(默认为未设置) builder.setBackoffPolicy(BackoffPolicy .constantBackoff(TimeValue.timeValueSeconds(1L), 3)); //设置一个恒定的后退策略，最初等待1秒钟，最多重试3次。有关更多选项，请参见BackoffPolicy.noBackoff(), BackoffPolicy.constantBackoff()和BackoffPolicy.exponentialBackoff(). 一旦批量处理器被创建，可以向它添加请求: IndexRequest one = new IndexRequest(\"posts\").id(\"1\") .source(XContentType.JSON, \"title\", \"In which order are my Elasticsearch queries executed?\"); IndexRequest two = new IndexRequest(\"posts\").id(\"2\") .source(XContentType.JSON, \"title\", \"Current status and upcoming changes in Elasticsearch\"); IndexRequest three = new IndexRequest(\"posts\").id(\"3\") .source(XContentType.JSON, \"title\", \"The Future of Federated Search in Elasticsearch\"); bulkProcessor.add(one); bulkProcessor.add(two); bulkProcessor.add(three); 请求将由BulkProcessor执行，它负责为每个批量请求调用BulkProcessor.Listener。 侦听器提供访问BulkRequest和BulkResponse的方法: BulkProcessor.Listener listener = new BulkProcessor.Listener() { @Override public void beforeBulk(long executionId, BulkRequest request) { int numberOfActions = request.numberOfActions(); //在每次执行BulkRequest之前调用，这个方法允许知道在BulkRequest中将要执行的操作的数量 logger.debug(\"Executing bulk [{}] with {} requests\", executionId, numberOfActions); } @Override public void afterBulk(long executionId, BulkRequest request, BulkResponse response) { if (response.hasFailures()) { //在每次执行BulkRequest后调用，该方法允许知道BulkResponse是否包含错误 logger.warn(\"Bulk [{}] executed with failures\", executionId); } else { logger.debug(\"Bulk [{}] completed in {} milliseconds\", executionId, response.getTook().getMillis()); } } @Override public void afterBulk(long executionId, BulkRequest request, Throwable failure) { logger.error(\"Failed to execute bulk\", failure); //如果BulkRequest失败，则调用该方法，该方法允许知道失败 } }; 一旦所有请求都添加到BulkProcessor中，就需要使用两种可用的关闭方法之一来关闭它的实例。 awaitClose()方法可用于等待，直到处理完所有请求或经过指定的等待时间: boolean terminated = bulkProcessor.awaitClose(30L, TimeUnit.SECONDS); //如果所有大容量请求都已完成，则该方法返回true如果在所有大容量请求完成之前等待时间已过，则该方法返回false close()方法可用于立即关闭批量处理器: bulkProcessor.close(); 这两种方法都会在关闭处理器之前刷新添加到处理器中的请求，并且禁止向其中添加任何新请求。 "},"java-multiget-api.html":{"url":"java-multiget-api.html","title":"JAVA实例：Multi-Get API","keywords":"","body":"JAVA实例：Multi-Get API multiGet API在一个http请求中并行执行多个获取请求。 Multi-Get Request MultiGetRequest的构造函数为空，你可以添加MultiGetRequest.Item到查询中。 MultiGetRequest request = new MultiGetRequest(); request.add(new MultiGetRequest.Item( \"index\", //索引 \"example_id\")); //文档id request.add(new MultiGetRequest.Item(\"index\", \"another_id\")); //添加另一个要提取的项目 可选参数 request.add(new MultiGetRequest.Item(\"index\", \"example_id\") .fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE)); //禁用源检索，默认情况下启用 String[] includes = new String[] {\"foo\", \"*r\"}; String[] excludes = Strings.EMPTY_ARRAY; FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes); request.add(new MultiGetRequest.Item(\"index\", \"example_id\") .fetchSourceContext(fetchSourceContext)); //为特定字段配置源包含 String[] includes = Strings.EMPTY_ARRAY; String[] excludes = new String[] {\"foo\", \"*r\"}; FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes); request.add(new MultiGetRequest.Item(\"index\", \"example_id\") .fetchSourceContext(fetchSourceContext)); //为特定字段配置源排除 request.add(new MultiGetRequest.Item(\"index\", \"example_id\") .storedFields(\"foo\")); //配置特定存储字段的检索(要求字段在映射中单独存储) MultiGetResponse response = client.mget(request, RequestOptions.DEFAULT); MultiGetItemResponse item = response.getResponses()[0]; String value = item.getResponse().getField(\"foo\").getValue(); //检索foo存储字段(要求该字段在映射中单独存储) request.add(new MultiGetRequest.Item(\"index\", \"with_routing\") .routing(\"some_routing\")); //路由值 request.add(new MultiGetRequest.Item(\"index\", \"with_version\") .versionType(VersionType.EXTERNAL) //版本 .version(10123L)); //版本类型 preference, realtime和refresh可以在主请求上设置，但不能在任何项目上设置: request.preference(\"some_preference\"); //偏好值 request.realtime(false);//将实时标志设置为false(默认true) request.refresh(true); //在检索文档之前执行刷新(默认false) 同步执行 当以下列方式执行多重网格请求时，客户端在继续执行代码之前，会等待多重网格响应返回: MultiGetResponse response = client.mget(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 也可以异步方式执行MultiGetRequest，以便客户端可以直接返回。用户需要通过向异步多获取方法传递请求和侦听器来指定如何处理响应或潜在故障: client.mgetAsync(request, RequestOptions.DEFAULT, listener); //要执行的多重请求和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 典型的multi-get监听器如下所示: listener = new ActionListener() { @Override public void onResponse(MultiGetResponse response) { //成功的时候执行 } @Override public void onFailure(Exception e) { //失败的时候执行 } }; Multi Get Response 返回的MultiGetResponse包含一个MultiGetItemResponse列表，按请求的顺序排列在GetResponse中。MultiGetResponse包含获取成功时的获取GetResponse或MultiGetResponse。失败则提示失败，成功看起来就像普通的GetResponse。 MultiGetItemResponse firstItem = response.getResponses()[0]; assertNull(firstItem.getFailure()); //getFailure返回null意味着没有失败。 GetResponse firstGet = firstItem.getResponse();//getResponse返回GetResponse。 String index = firstItem.getIndex(); String id = firstItem.getId(); if (firstGet.isExists()) { long version = firstGet.getVersion(); String sourceAsString = firstGet.getSourceAsString(); //以字符串形式检索文档 Map sourceAsMap = firstGet.getSourceAsMap();//以Map的形式检索文档 byte[] sourceAsBytes = firstGet.getSourceAsBytes(); //以 byte[]形式检索文档 } else { //处理找不到文档的情况。请注意，虽然返回的响应有404个状态代码，但返回的是有效的GetResponse，而不是引发的异常。这种响应不包含任何源文档，其isExists方法返回false。 } 当对不存在的索引执行的子请求之一getFailure将包含异常: assertNull(missingIndexItem.getResponse());//getResponse为空。 Exception e = missingIndexItem.getFailure().getFailure();//getFailure不是并且包含异常。 ElasticsearchException ee = (ElasticsearchException) e; // 这个异常是一个ElasticsearchException // TODO status is broken! fix in a followup // assertEquals(RestStatus.NOT_FOUND, ee.status());//它的状态为“未找到”。如果不是多重获取，它应该是一个HTTP 404。 assertThat(e.getMessage(), containsString(\"reason=no such index [missing_index]\"));//getMessage解释了原因。 如果请求了特定的文档版本，并且现有文档具有不同的版本号，则会引发版本冲突: MultiGetRequest request = new MultiGetRequest(); request.add(new MultiGetRequest.Item(\"index\", \"example_id\") .version(1000L)); MultiGetResponse response = client.mget(request, RequestOptions.DEFAULT); MultiGetItemResponse item = response.getResponses()[0]; assertNull(item.getResponse());//getResponse为空。 Exception e = item.getFailure().getFailure();//getFailure不是并且包含异常。 ElasticsearchException ee = (ElasticsearchException) e;//这个异常是一个ElasticsearchException // TODO status is broken! fix in a followup // assertEquals(RestStatus.CONFLICT, ee.status());//它的状态为CONFLICT。如果不是多重获取，它应该是一个HTTP 409。 assertThat(e.getMessage(), containsString(\"version conflict, current version [1] is \" + \"different than the one provided [1000]\")); //getMessage解释了实际原因 "},"java-reindex-request.html":{"url":"java-reindex-request.html","title":"JAVA实例：Reindex API","keywords":"","body":"JAVA实例：Reindex API ReindexRequest ReindexRequest可用于将文档从一个或多个索引复制到目标索引中。 它需要一个现有的源索引和一个可能存在也可能不存在的目标索引。Reindex不会尝试设置目标索引，也不会复制源索引的设置。您应该在运行_reindex操作之前设置目标索引，包括设置映射、碎片计数、副本等。 ReindexRequest的最简单形式如下: ReindexRequest request = new ReindexRequest(); //创建ReindexRequest request.setSourceIndices(\"source1\", \"source2\"); //添加要从源中复制的列表 request.setDestIndex(\"dest\"); //添加目标索引 目标元素可以像索引API一样配置来控制乐观并发控制。忽略versionType(如上)或将其设置为内部将导致Elasticsearch盲目地将文档转储到目标中。将版本类型设置为外部将导致Elasticsearch保留源版本，创建任何丢失的文档，并更新目标索引中版本比源索引中版本旧的文档。 request.setDestVersionType(VersionType.EXTERNAL); //设置versionType为EXTERNAL 将opType设置为create导致_reindex仅在目标索引中创建丢失的文档。所有现有文档都将导致版本冲突。默认opType是index。 request.setDestOpType(\"create\"); //设置versionType为create 默认情况下，版本冲突会中止_reindex进程，但您可以用以下方法来计算它们: request.setConflicts(\"proceed\"); //设置版本冲突时继续 您可以通过添加查询来限制文档。 request.setSourceQuery(new TermQueryBuilder(\"user\", \"kimchy\")); /仅复制字段用户设置为kimchy的文档 也可以通过设置大小来限制已处理文档的数量。 request.setSize(10); //只拷贝10个文档 默认情况下_reindex单次可以处理1000个文档。您可以使用sourceBatchSize更改批处理大小。 request.setSourceBatchSize(100); //单次处理100个文档 Reindex还可以通过指定管道来使用摄取功能。 request.setDestPipeline(\"my_pipeline\"); //设置管线为my_pipeline 如果您想从源索引中获得一组特定的文档，您需要使用sort。如果可能的话，最好选择一个更有选择性的查询，而不是大小和排序。 request.addSortField(\"field1\", SortOrder.DESC); //将降序排序添加到`field1` request.addSortField(\"field2\", SortOrder.ASC); //将升序排序添加到field2 ReindexRequest还支持修改文档的脚本。它还允许您更改文档的元数据。下面的例子说明了这一点。 request.setScript( new Script( ScriptType.INLINE, \"painless\", \"if (ctx._source.user == 'kimchy') {ctx._source.likes++;}\", Collections.emptyMap())); //设置脚本来增加用户kimchy的所有文档中的likes字段。 ReindexRequest支持从远程Elasticsearch集群重新索引。当使用远程群集时，应该在RemoteInfo对象中指定查询，而不是使用setSourceQuery。如果同时设置了远程信息和源查询，则会在请求过程中导致验证错误。原因是远程Elasticsearch可能不理解现代查询构建器构建的查询。远程集群支持一直工作到Elasticsearch0.90，从那时起查询语言发生了变化。当达到旧版本时，用JSON手工编写查询更安全。 request.setRemoteInfo( new RemoteInfo( \"http\", remoteHost, remotePort, null, new BytesArray(new MatchAllQueryBuilder().toString()), user, password, Collections.emptyMap(), new TimeValue(100, TimeUnit.MILLISECONDS), new TimeValue(100, TimeUnit.SECONDS) ) ); //设置远程elastic集群 ReindexRequest也有助于使用切片滚动对_uid进行切片来自动并行化。使用设置切片指定要使用的切片数量。 request.setSlices(2); //设置使用的切片数 ReindexRequest使用Scroll参数来控制它保持“搜索上下文”活动的时间。 request.setScroll(TimeValue.timeValueMinutes(10)); //设置滚动时间 可选参数 除了上述选项之外，还可以选择提供以下参数: request.setTimeout(TimeValue.timeValueMinutes(2)); //等待重新索引请求作为时间值执行的超时 request.setRefresh(true); //调用reindex后刷新索引 同步执行 当以下列方式执行ReindexRequest时，客户端在继续执行代码之前，会等待返回BulkByScrollResponse: BulkByScrollResponse bulkResponse = client.reindex(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 执行ReindexRequest也可以异步方式完成，以便客户端可以直接返回。用户需要通过将请求和侦听器传递给异步reindex方法来指定如何处理响应或潜在故障: client.reindexAsync(request, RequestOptions.DEFAULT, listener); //要执行的ReindexRequest和执行完成时要使用的ActionListener 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 reindex的典型侦听器如下: listener = new ActionListener() { @Override public void onResponse(BulkByScrollResponse bulkResponse) { //成功的时候执行 } @Override public void onFailure(Exception e) { //失败的时候执行 } }; 重新索引任务提交 也可以使用Task API提交一个eindexRequest，而不是等待它完成。这相当于将等待完成标志设置为false的REST请求。 ReindexRequest reindexRequest = new ReindexRequest(); //ReindexRequest的构造方式与同步方法相同 reindexRequest.setSourceIndices(sourceIndex); reindexRequest.setDestIndex(destinationIndex); reindexRequest.setRefresh(true); TaskSubmissionResponse reindexSubmission = highLevelClient() .submitReindexTask(reindexRequest, RequestOptions.DEFAULT); //提交方法返回包含任务标识符的TaskSubmissionResponse。 String taskId = reindexSubmission.getTask(); //任务标识符可用于获取已完成任务的响应。 ReindexResponse 返回的BulkByScrollResponse包含有关已执行操作的信息，并允许迭代每个结果，如下所示: TimeValue timeTaken = bulkResponse.getTook(); //获取总时间 boolean timedOut = bulkResponse.isTimedOut(); //检查请求是否超时 long totalDocs = bulkResponse.getTotal(); //获取处理的文档总数 long updatedDocs = bulkResponse.getUpdated(); //已更新的文档数 long createdDocs = bulkResponse.getCreated(); //创建的文档数 long deletedDocs = bulkResponse.getDeleted(); //已删除的文档数 long batches = bulkResponse.getBatches(); //已执行的批次数量 long noops = bulkResponse.getNoops(); //跳过的文档数 long versionConflicts = bulkResponse.getVersionConflicts(); //版本冲突的数量 long bulkRetries = bulkResponse.getBulkRetries(); //请求必须重试批量索引操作的次数 long searchRetries = bulkResponse.getSearchRetries(); //请求必须重试搜索操作的次数 TimeValue throttledMillis = bulkResponse.getStatus().getThrottled(); //如果当前处于睡眠状态，此请求限制自身的总时间不包括当前限制时间 TimeValue throttledUntilMillis = bulkResponse.getStatus().getThrottledUntil(); //任何当前油门休眠的剩余延迟，或者如果没有休眠，则为0 List searchFailures = bulkResponse.getSearchFailures(); //搜索阶段失败 List bulkFailures = bulkResponse.getBulkFailures(); //批量索引操作期间失败 "},"java-update-by-query-api.html":{"url":"java-update-by-query-api.html","title":"JAVA实例：Update By Query API","keywords":"","body":"JAVA实例：Update By Query API Update By Query Request UpdateByQueryRequest可用于更新索引中的文档。 它需要执行更新的现有索引(或一组索引)。 更新查询的最简单形式如下: UpdateByQueryRequest request = new UpdateByQueryRequest(\"source1\", \"source2\"); //在一组索引上创建UpdateByQueryRequest。 默认情况下，版本冲突会中止UpdateByQueryRequest进程，但您可以用以下方法来计算它们: request.setConflicts(\"proceed\"); //设置版本冲突时继续 您可以通过添加查询来限制文档。 request.setQuery(new TermQueryBuilder(\"user\", \"kimchy\")); //仅复制字段用户设置为kimchy的文档 也可以通过设置大小来限制已处理文档的数量。 request.setSize(10); //只拷贝10个文档 默认情况下UpdateByQueryRequest单次可以处理1000个文档。您可以使用sourceBatchSize更改批处理大小。 request.setSourceBatchSize(100); //单次处理100个文档 Reindex还可以通过指定管道来使用摄取功能。 request.setDestPipeline(\"my_pipeline\"); //设置管线为my_pipeline UpdateByQueryRequest还支持修改文档的脚本: request.setScript( new Script( ScriptType.INLINE, \"painless\", \"if (ctx._source.user == 'kimchy') {ctx._source.likes++;}\", Collections.emptyMap())); //设置脚本来增加用户kimchy的所有文档中的likes字段。 UpdateByQueryRequest可以使用带设置切片的切片滚动来并行化: request.setSlices(2); //设置要使用的切片数量 UpdateByQueryRequest使用Scroll参数来控制它将“搜索上下文”保持多长时间。 request.setScroll(TimeValue.timeValueMinutes(10)); //设置滚动时间 如果您提供了路由，则路由将被复制到滚动查询，从而将该过程限制在与该路由值匹配的碎片上。 request.setRouting(\"=cat\"); //设置路由 可选参数 除了上述选项之外，还可以选择提供以下参数: request.setTimeout(TimeValue.timeValueMinutes(2)); //等待按查询请求更新作为时间值执行的超时时间 request.setRefresh(true); //通过查询调用更新后刷新索引 request.setIndicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN); //设置索引选项 同步执行 当以下列方式执行UpdateByQueryRequest时，客户端在继续执行代码之前，会等待返回UpdateByQueryResponse: BulkByScrollResponse bulkResponse = client.updateByQuery(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 也可以异步方式执行UpdateByQueryRequest，以便客户端可以直接返回。用户需要通过将请求和侦听器传递给异步逐查询更新方法来指定如何处理响应或潜在故障: client.updateByQueryAsync(request, RequestOptions.DEFAULT, listener);//要执行的UpdateByQueryRequest和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 pdate-by-query的典型侦听器如下所示: listener = new ActionListener() { @Override public void onResponse(BulkByScrollResponse bulkResponse) { //成功的时候执行 } @Override public void onFailure(Exception e) { //失败的时候执行 } }; UpdateByQueryResponse 返回的UpdateByQueryResponse包含有关已执行操作的信息，并允许迭代每个结果，如下所示: TimeValue timeTaken = bulkResponse.getTook(); //获取总时间 boolean timedOut = bulkResponse.isTimedOut(); //检查请求是否超时 long totalDocs = bulkResponse.getTotal(); //获取处理的文档总数 long updatedDocs = bulkResponse.getUpdated(); //已更新的文档数 long deletedDocs = bulkResponse.getDeleted(); //已删除的文档数 long batches = bulkResponse.getBatches(); //已执行的批次数量 long noops = bulkResponse.getNoops(); //跳过的文档数 long versionConflicts = bulkResponse.getVersionConflicts(); //版本冲突的数量 long bulkRetries = bulkResponse.getBulkRetries(); //请求批量索引操作的重试次数 long searchRetries = bulkResponse.getSearchRetries(); //请求搜索操作重试的次数 TimeValue throttledMillis = bulkResponse.getStatus().getThrottled(); //如果当前处于睡眠状态，此请求限制自身的总时间不包括当前限制时间 TimeValue throttledUntilMillis = bulkResponse.getStatus().getThrottledUntil(); //任何当前休眠的剩余延迟，或者如果没有休眠，则为0 List searchFailures = bulkResponse.getSearchFailures(); //获取搜索的失败 List bulkFailures = bulkResponse.getBulkFailures(); //获取批量索引操作期间的失败 "},"java-delete-by-query-api.html":{"url":"java-delete-by-query-api.html","title":"JAVA实例：Delete By Query API","keywords":"","body":"JAVA实例：Delete By Query API DeleteByQueryRequest DeleteByQueryRequest可用于从索引中删除文档。它需要一个要执行删除的现有索引(或一组索引)。 DeleteByQueryRequest的最简单形式如下，它删除索引中的所有文档: DeleteByQueryRequest request = new DeleteByQueryRequest(\"source1\", \"source2\"); //在一组索引上创建DeleteByQueryRequest。 默认情况下，版本冲突会中止DeleteByQueryRequest进程，但您可以用以下方法对它们进行计数: request.setConflicts(\"proceed\"); //设置版本冲突时继续 您可以通过添加查询来限制文档。 request.setQuery(new TermQueryBuilder(\"user\", \"kimchy\")); //仅复制字段用户设置为kimchy的文档 也可以通过设置大小来限制已处理文档的数量。 request.setSize(10); //只拷贝十个文档 默认情况下，DeleteByQueryRequest可以批量处理1000个文档。您可以使用setBatchSize更改批处理大小。 request.setBatchSize(100); //单批处理100份文件 DeleteByQueryRequest也可以使用带有设置切片的切片滚动来并行化: request.setSlices(2); //设置要使用的切片数量 DeleteByQueryRequest使用Scroll参数来控制它将“搜索上下文”保持多长时间。 request.setScroll(TimeValue.timeValueMinutes(10)); //设置滚动时间 如果您提供了路由，则路由将被复制到滚动查询，从而将该过程限制在与该路由值匹配的碎片上。 request.setRouting(\"=cat\"); //设置路由 可选参数 除了上述选项之外，还可以选择提供以下参数: request.setTimeout(TimeValue.timeValueMinutes(2)); //等待按查询删除请求作为时间值执行的超时 request.setRefresh(true); //调用查询删除后刷新索引 request.setIndicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN); //设置索引选项 同步执行 当以下列方式执行DeleteByQueryRequest时，客户端会在继续执行代码之前等待返回DeleteByQueryResponse: BulkByScrollResponse bulkResponse = client.deleteByQuery(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseExceptio作为抑制异常添加到其中。 异步执行 也可以异步方式执行DeleteByQueryRequest，以便客户端可以直接返回。用户需要通过将请求和侦听器传递给异步按查询删除方法来指定如何处理响应或潜在故障: client.deleteByQueryAsync(request, RequestOptions.DEFAULT, listener); //要执行的DeleteByQueryRequest和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。一旦完成，如果执行成功完成，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 delete-by-query的典型侦听器如下所示: listener = new ActionListener() { @Override public void onResponse(BulkByScrollResponse bulkResponse) { //成功的时候调用 } @Override public void onFailure(Exception e) { //失败的时候调用 } }; DeleteByQueryResponse 返回的DeleteByQueryResponse包含有关已执行操作的信息，并允许迭代每个结果，如下所示: TimeValue timeTaken = bulkResponse.getTook(); //获取总时间 boolean timedOut = bulkResponse.isTimedOut(); //检查请求是否超时 long totalDocs = bulkResponse.getTotal(); //获取处理的文档总数 long deletedDocs = bulkResponse.getDeleted(); //已删除的文档数 long batches = bulkResponse.getBatches(); //已执行的批次数量 long noops = bulkResponse.getNoops(); //跳过的文档数 long versionConflicts = bulkResponse.getVersionConflicts(); //版本冲突的数量 long bulkRetries = bulkResponse.getBulkRetries(); //请求必须重试批量索引操作的次数 long searchRetries = bulkResponse.getSearchRetries(); //请求必须重试搜索操作的次数 TimeValue throttledMillis = bulkResponse.getStatus().getThrottled(); //如果当前处于睡眠状态，此请求限制自身的总时间不包括当前限制时间 TimeValue throttledUntilMillis = bulkResponse.getStatus().getThrottledUntil(); //任何当前休眠的剩余延迟，或者如果没有休眠，则为0 List searchFailures = bulkResponse.getSearchFailures(); //搜索阶段失败 List bulkFailures = bulkResponse.getBulkFailures(); //批量索引操作期间失败 "},"java-rethrottle-api.html":{"url":"java-rethrottle-api.html","title":"JAVA实例：Rethrottle API","keywords":"","body":"JAVA实例：Rethrottle API RethrottleRequest RethrottleRequest可用于更改正在运行的reindex, update-by-query或delete-by-query的当前限制，或者完全禁用任务的限制，它要求更改任务的任务标识。 在其最简单的形式中，您可以使用它来禁用运行任务的throttling，方法如下: RethrottleRequest request = new RethrottleRequest(taskId); //创建一个RethrottleRequest，禁用特定任务id的限制 通过提供requestsPerSecond参数，请求将现有任务限制更改为指定值: RethrottleRequest request = new RethrottleRequest(taskId, 100.0f); //将任务限制更改为每秒100个请求 根据reindex, update-by-query和delete-by-query任务是否应该重新排序，可以使用三种适当方法之一来执行重新排序请求: client.reindexRethrottle(request, RequestOptions.DEFAULT); //执行重新索引重新调用请求 client.updateByQueryRethrottle(request, RequestOptions.DEFAULT); //按查询更新也是如此 client.deleteByQueryRethrottle(request, RequestOptions.DEFAULT); //按查询删除也是如此 异步执行 rethrottle请求的异步执行要求将rethrottle请求实例和动作监听器实例都传递给异步方法: client.reindexRethrottleAsync(request, RequestOptions.DEFAULT, listener); //异步执行重新索引重新计时 client.updateByQueryRethrottleAsync(request, RequestOptions.DEFAULT, listener); //按查询更新也是如此 client.deleteByQueryRethrottleAsync(request, RequestOptions.DEFAULT, listener); //按查询删除也是如此 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。典型的监听器是这样的: listener = new ActionListener() { @Override public void onResponse(ListTasksResponse response) { //成功的时候调用 } @Override public void onFailure(Exception e) { //失败的时候调用 } }; Rethrottle Response Rethrottling以ListTasksResponse的形式返回已经重新启动的任务。List Tasks API将详细描述该响应对象的结构。 "},"java-multi-term-vectors-api.html":{"url":"java-multi-term-vectors-api.html","title":"JAVA实例：Multi Term Vectors API","keywords":"","body":"JAVA实例：Multi Term Vectors API Multi Term Vectors API允许一次获得多个向量。 Multi Term Vectors Request 创建MultiTermVectorsRequest有两种方法。 第一种方法是创建一个空的MultiTermVectorsRequest，然后向其中添加单独的TermVectorsRequest求。 MultiTermVectorsRequest request = new MultiTermVectorsRequest(); //创建一个空的MultiTermVectorsRequest。 TermVectorsRequest tvrequest1 = new TermVectorsRequest(\"authors\", \"1\"); tvrequest1.setFields(\"user\"); request.add(tvrequest1); //将第一个术语向量请求添加到多术语向量请求中。 XContentBuilder docBuilder = XContentFactory.jsonBuilder(); docBuilder.startObject().field(\"user\", \"guest-user\").endObject(); TermVectorsRequest tvrequest2 = new TermVectorsRequest(\"authors\", docBuilder); request.add(tvrequest2); //将人工文档的第二个术语请求添加到多术语请求中。 当所有TermVectorsRequest共享相同的参数(如索引和其他设置)时，可以使用第二种方法。在这种情况下，可以创建一个模板TermVectorsRequest，并设置所有必要的设置，该模板请求可以与执行这些请求的所有文档id一起传递给MultiTermVectorsRequest。 TermVectorsRequest tvrequestTemplate = new TermVectorsRequest(\"authors\", \"fake_id\"); //创建模板TermVectorsRequest。 tvrequestTemplate.setFields(\"user\"); String[] ids = {\"1\", \"2\"}; MultiTermVectorsRequest request = new MultiTermVectorsRequest(ids, tvrequestTemplate); //将文档的id和模板传递给MultiTermVectorsRequest。 同步执行 当以下列方式执行MultiTermVectorsRequest时，客户端会在继续执行代码之前等待返回MultiTermVectorsResponse: MultiTermVectorsResponse response = client.mtermvectors(request, RequestOptions.DEFAULT); 同步调用可能会在高级REST客户端中解析REST响应失败、请求超时或类似服务器没有响应的情况下抛出IOException。 在服务器返回4xx或5xx错误代码的情况下，高级客户端会尝试解析响应主体错误详细信息，然后抛出一个通用的ElasticsearchException，并将原始ResponseException作为抑制异常添加到其中。 异步执行 也可以异步方式执行MultiTermVectorsRequest，以便客户端可以直接返回。用户需要通过将请求和侦听器传递给异步MultiTermVectors方法来指定如何处理响应或潜在故障: client.mtermvectorsAsync( request, RequestOptions.DEFAULT, listener); 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。失败场景和预期异常与同步执行情况相同。 MultiTermVectors的典型监听器如下所示: listener = new ActionListener() { @Override public void onResponse(MultiTermVectorsResponse mtvResponse) { } @Override public void onFailure(Exception e) { } }; Multi Term Vectors Response MultiTermVectorsResponse允许获得TermVectorsResponse的列表，每个响应都可以按照Term Vectors API中的描述进行检查。 List tvresponseList = response.getTermVectorsResponses(); //获取MultiTermVectorsResponse列表 if (tvresponseList != null) { for (TermVectorsResponse tvresponse : tvresponseList) { } } "},"java-search-api.html":{"url":"java-search-api.html","title":"JAVA实例：搜索API","keywords":"","body":"JAVA实例：搜索API 大多数搜索API是多索引、多类型的，Explain API端点除外。 路由 执行搜索时，它将被广播到所有索引/索引碎片(副本之间的循环)。可以通过提供路由参数来控制搜索哪些碎片。例如，索引tweets时，路由值可以是用户名: POST /twitter/tweet?routing=kimchy { \"user\" : \"kimchy\", \"postDate\" : \"2009-11-15T14:12:12\", \"message\" : \"trying out Elasticsearch\" } 在这种情况下，如果我们只想在tweets中搜索特定用户，我们可以将其指定为路由，导致搜索只命中相关碎片: POST /twitter/tweet/_search?routing=kimchy { \"query\": { \"bool\" : { \"must\" : { \"query_string\" : { \"query\" : \"some query string here\" } }, \"filter\" : { \"term\" : { \"user\" : \"kimchy\" } } } } } 路由参数可以是用逗号分隔的字符串表示的多值。这将导致命中路由值匹配的相关碎片。 统计组 搜索可以与统计组相关联，统计组维护每个组的统计聚合。稍后可以特别使用索引统计应用编程接口来检索它。例如，这里有一个搜索主体请求，它将请求与两个不同的组相关联: POST /_search { \"query\" : { \"match_all\" : {} }, \"stats\" : [\"group1\", \"group2\"] } 全局搜索超时 作为搜索请求的一部分，单个搜索可以设置超时。由于搜索请求可以来自许多来源，Elasticsearch具有动态集群级全局搜索超时的设置，适用于在搜索请求正文中未设置超时的所有请求。默认值是无全局超时。设置键是search.default_search_timeout，可以使用群集更新设置端点进行设置。将该值设置为-1将全局搜索超时重置为无超时。 搜索取消 我们可以使用标准任务取消机制取消搜索。默认情况下，正在运行的搜索只检查它是否在段边界上被取消，因此取消可能会被较大的段延迟。通过将动态集群级设置search . low_level_cancel设置为true，可以提高搜索取消响应速度。然而，它伴随着更频繁的取消检查的额外开销，这在大型快速运行的搜索查询中是显而易见的。更改此设置只会影响更改后开始的搜索。 "},"java-search-api-search.html":{"url":"java-search-api-search.html","title":"JAVA实例：搜索","keywords":"","body":"JAVA实例：搜索 搜索API允许您执行搜索查询，并返回与该查询匹配的搜索命中。查询可以使用简单的查询字符串作为参数来提供，也可以使用请求体来提供。 多索引搜索 所有搜索API都支持多索引语法，可以跨多个索引应用。例如，我们可以搜索twitter索引中的所有文档: GET /twitter/_search?q=user:kimchy 我们还可以在多个索引中搜索带有特定标签的所有文档(例如，当每个用户有一个索引时): GET /kimchy,elasticsearch/_search?q=tag:wow 或者，我们可以使用_all搜索所有可用的索引: GET /_all/_search?q=tag:wow 部分回应 为了确保快速响应，如果一个或多个碎片出现故障，搜索API将使用部分结果进行响应。有关更多信息，请参见碎片故障。 "},"java-search-uri-request.html":{"url":"java-search-uri-request.html","title":"JAVA实例：URI搜索","keywords":"","body":"JAVA实例：URI搜索 通过提供请求参数，可以纯粹使用URI执行搜索请求。在使用这种模式执行搜索时，并不是所有的搜索选项都是公开的，但是对于快速的“curl tests”来说，这是很方便的。下面是一个例子: 下面是一个简单的响应例子 { \"timed_out\": false, \"took\": 62, \"_shards\":{ ​ \"total\" : 1, ​ \"successful\" : 1, ​ \"skipped\" : 0, ​ \"failed\" : 0 }, \"hits\":{ ​ \"total\" : { ​ \"value\": 1, ​ \"relation\": \"eq\" ​ }, ​ \"max_score\": 1.3862944, ​ \"hits\" : [ ​ { ​ \"_index\" : \"twitter\", ​ \"_type\" : \"_doc\", ​ \"_id\" : \"0\", ​ \"_score\": 1.3862944, ​ \"_source\" : { ​ \"user\" : \"kimchy\", ​ \"date\" : \"2009-11-15T14:12:12\", ​ \"message\" : \"trying out Elasticsearch\", ​ \"likes\": 0 ​ } ​ } ​ ] } } 参数 URI搜索允许使用以下参数: q：查询字符串。 df：查询中未定义字段前缀时使用的默认字段 analyzer：分析查询字符串时要使用的分析器名称。 analyze_wildcard：是否应该分析通配符和前缀查询。默认为false。 batched_reduce_size：协调节点上应立即减少的碎片结果的数量。如果请求中的潜在碎片数量可能很大，则该值应用作保护机制，以减少每个搜索请求的内存开销。 default_operator：要使用的默认运算符可以是“与”或“或”。默认为“或”。 lenient：如果设置为true，将导致忽略基于格式的异常。默认为false。 explain：对于每一次命中，包含一个如何计算命中得分的解释。 source：设置为false以禁用对_source字段的检索。您也可以通过使用 source includes & source excludes来检索文档的一部分(有关更多详细信息，请参见请求正文文档) stored_fields：每次命中时要返回的文档的选择性存储字段，以逗号分隔。不指定任何值将导致没有字段返回。 sort：要执行的排序。可以是字段名的形式，也可以是字段名:ASC/字段名:desc。字段名可以是文档中的实际字段，也可以是表示基于分数排序的特殊分数名。可以有几个排序参数(顺序很重要)。 track_scores：排序时，设置为true，以便仍然跟踪分数并将其作为每次命中的一部分返回。 track_total_hits：默认值为10，000。设置为false以禁用对匹配查询的命中总数的跟踪。它还接受一个整数，在本例中，该整数代表要精确计数的命中数。(有关更多详细信息，请参见请求正文文档)。 timeout：搜索超时，将搜索请求限定在指定的时间值内执行，过期时点击次数累计到该时间点。默认为无超时。 terminateafter：为每个碎片收集的最大文档数，一旦达到该数量，查询执行将提前终止。如果设置，响应将有一个布尔字段terminated_early，以指示查询执行是否实际上已终止_early。默认为无终止之后。 from：从命中的索引开始返回。默认为0。 size：要返回的命中数。默认值为10。 search_type：要执行的搜索操作的类型。可以是dfs_query_then_fetch或query_then_fetch。默认为query_then_fetch。有关可以执行的不同搜索类型的更多详细信息，请参见搜索类型。 allow_partial_search_results：如果请求会产生部分结果，则设置为false返回整体失败。默认值为true，这将在超时或部分失败的情况下允许部分结果。可以使用群集级别的设置搜索来控制此默认值。 "},"java-rest-high-search-scroll-api.html":{"url":"java-rest-high-search-scroll-api.html","title":"JAVA实例：Search Scroll API","keywords":"","body":"JAVA实例：Search Scroll API Scroll API可用于从搜索请求中检索大量结果。 为了使用scrolling，需要按照指定的顺序执行以下步骤。 初始化搜索scroll上下文 必须执行带有scroll参数的初始搜索请求，以通过Search API初始化scroll会话。处理此搜索请求时，Elasticsearch会检测scroll参数的存在，并在相应的时间间隔内保持搜索上下文有效。 SearchRequest searchRequest = new SearchRequest(\"posts\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(matchQuery(\"title\", \"Elasticsearch\")); searchSourceBuilder.size(size); //创建搜索请求及其对应的搜索源生成器。还可以选择设置大小来控制一次检索多少个结果。 searchRequest.source(searchSourceBuilder); searchRequest.scroll(TimeValue.timeValueMinutes(1L)); //设置scroll间隔 SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); String scrollId = searchResponse.getScrollId(); //读取返回的scroll id，该id指向保持活动状态的搜索上下文，在以下搜索scroll调用中将需要它 SearchHits hits = searchResponse.getHits(); //检索第一批搜索命中 检索所有相关文档 第二步，接收到的scroll标识符必须设置为SearchScrollRequest以及新的scroll间隔，并通过searchScroll方法发送。Elasticsearch返回另一批带有新scroll标识符的结果。然后，这个新的scroll标识符可以在后续的SearchScrollRequest中使用，以检索下一批结果，依此类推。这个过程应该在一个循环中重复，直到不再返回结果，这意味着scroll已经用尽，并且所有匹配的文档已经被检索到。 SearchScrollRequest scrollRequest = new SearchScrollRequest(scrollId); //通过设置所需的scroll id和scroll间隔来创建搜索scroll请求 scrollRequest.scroll(TimeValue.timeValueSeconds(30)); SearchResponse searchScrollResponse = client.scroll(scrollRequest, RequestOptions.DEFAULT); scrollId = searchScrollResponse.getScrollId(); //读取新的scrollid，该id指向保持活动状态的搜索上下文，并且在接下来的搜索scroll调用中将需要它 hits = searchScrollResponse.getHits(); //检索另一批搜索命中 assertEquals(3, hits.getTotalHits().value); assertEquals(1, hits.getHits().length); assertNotNull(scrollId); 清除scroll上下文 最后，可以使用清除Clear Scroll API删除最后一个scroll标识符，以便释放搜索上下文。scroll 到期时会自动发生这种情况，但最好在scroll 会话完成后立即进行。 可选参数 构造搜索请求时，可以选择提供以下参数: scrollRequest.scroll(TimeValue.timeValueSeconds(60L)); //滚动时间间隔 scrollRequest.scroll(\"60s\"); //以字符串形式滚动间隔 如果没有为搜索滚动请求设置滚动值，一旦初始滚动时间到期(即初始搜索请求中设置的滚动时间)，搜索上下文将到期。 同步执行 SearchResponse searchResponse = client.scroll(scrollRequest, RequestOptions.DEFAULT); 异步执行 SearchScrollRequest的异步执行要求将搜索滚动请求实例和操作侦听器实例都传递给异步方法: client.scrollAsync(scrollRequest, RequestOptions.DEFAULT, scrollListener); //要执行的搜索请求和执行完成时要使用的操作侦听器 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。 搜索响应的典型侦听器如下: ActionListener scrollListener = new ActionListener() { @Override public void onResponse(SearchResponse searchResponse) { //成功的时候执行 } @Override public void onFailure(Exception e) { //出错的时候执行 } }; 响应 search scroll API 返回一个 SearchResponse对象，与search API 相同。 完整的例子 final Scroll scroll = new Scroll(TimeValue.timeValueMinutes(1L)); SearchRequest searchRequest = new SearchRequest(\"posts\"); searchRequest.scroll(scroll); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(matchQuery(\"title\", \"Elasticsearch\")); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); //通过发送初始搜索请求来初始化搜索上下文 String scrollId = searchResponse.getScrollId(); SearchHit[] searchHits = searchResponse.getHits().getHits(); while (searchHits != null && searchHits.length > 0) { //通过循环调用搜索滚动api来检索所有搜索命中，直到没有文档返回 //处理返回的搜索结果 SearchScrollRequest scrollRequest = new SearchScrollRequest(scrollId); //创建一个新的搜索滚动请求，保存最后返回的滚动标识符和滚动间隔 scrollRequest.scroll(scroll); searchResponse = client.scroll(scrollRequest, RequestOptions.DEFAULT); scrollId = searchResponse.getScrollId(); searchHits = searchResponse.getHits().getHits(); } ClearScrollRequest clearScrollRequest = new ClearScrollRequest(); //完成滚动后，清除滚动上下文 clearScrollRequest.addScrollId(scrollId); ClearScrollResponse clearScrollResponse = client.clearScroll(clearScrollRequest, RequestOptions.DEFAULT); boolean succeeded = clearScrollResponse.isSucceeded(); "},"java-rest-high-clear-scroll-api.html":{"url":"java-rest-high-clear-scroll-api.html","title":"JAVA实例：Clear Scroll API","keywords":"","body":"JAVA实例：Clear Scroll API Clear Scroll API 当滚动超时时，Search Scroll API使用的搜索上下文会自动删除。但是建议使用Clear Scroll API，一旦不再需要搜索上下文，就立即释放它们。 ClearScrollRequest 可以按如下方式创建一个ClearScrollRequest: ClearScrollRequest request = new ClearScrollRequest(); //创建一个新的ClearScrollRequest request.addScrollId(scrollId); //将滚动id添加到要清除的滚动标识符列表中 提供滚动标识符 ClearScrollRequest允许在单个请求中清除一个或多个滚动标识符。 滚动标识符可以一个接一个地添加到请求中: request.addScrollId(scrollId); 或者一起使用: request.setScrollIds(scrollIds); 同步方式执行 ClearScrollResponse response = client.clearScroll(request, RequestOptions.DEFAULT); 异步方式执行 ClearScrollRequest的异步执行需要将ClearScrollRequest实例和ActionListener实例都传递给异步方法: client.clearScrollAsync(request, RequestOptions.DEFAULT, listener); 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。 一个典型的ClearScrollResponse监听器像下面这样： ActionListener listener = new ActionListener() { @Override public void onResponse(ClearScrollResponse clearScrollResponse) { //成功的时候调用 } @Override public void onFailure(Exception e) { //失败的时候调用 } }; ClearScrollResponse 返回的ClearScrollResponse允许检索关于发布的搜索上下文的信息: boolean success = response.isSucceeded(); //如果请求成功返回true int released = response.getNumFreed(); //返回发布的搜索上下文的数量 "},"java-rest-high-multi-search-api.html":{"url":"java-rest-high-multi-search-api.html","title":"JAVA实例：Multi-Search API","keywords":"","body":"JAVA实例：Multi-Search API Multi-Search API multiSearch API在一个http请求中并行执行多个搜索请求。 Multi-SearchRequest MultiSearchRequest的构造函数是空的，您可以将所有希望执行的搜索添加到其中: MultiSearchRequest request = new MultiSearchRequest(); //创建一个空的MultiSearchRequest 。 SearchRequest firstSearchRequest = new SearchRequest();//创建一个空的SearchRequest，并像常规搜索一样填充它。 SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\"user\", \"kimchy\")); firstSearchRequest.source(searchSourceBuilder); request.add(firstSearchRequest); //将SearchRequest添加到MultiSearchRequest中。 SearchRequest secondSearchRequest = new SearchRequest(); //构建第二个SearchRequest，并将其添加到MultiSearchRequest中。 searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\"user\", \"luca\")); secondSearchRequest.source(searchSourceBuilder); request.add(secondSearchRequest); 可选参数 MultiSearchRequest支持所有的SearchRequest参数，例如： SearchRequest searchRequest = new SearchRequest(\"posts\"); //将请求限制为索引 同步方式执行 MultiSearchResponse response = client.msearch(request, RequestOptions.DEFAULT); 异步方式执行 client.searchAsync(searchRequest, RequestOptions.DEFAULT, listener); 异步方法不会阻塞并立即返回。如果执行成功，则使用onResponse方法回调操作侦听器，如果执行失败，则使用onFailure方法回调操作侦听器。 MultiSearchResponse的典型监听器如下所示: ActionListener listener = new ActionListener() { @Override public void onResponse(MultiSearchResponse response) { //成功的时候调用 } @Override public void onFailure(Exception e) { //失败的时候调用 } }; MultiSearchResponse 通过执行MultiSearchRequest方法返回MultiSearchResponse。 如果请求失败，每个MultiSearchResponse.Item都包含getFailure中的异常；如果请求成功，则包含getResponse中的搜索响应: MultiSearchResponse.Item firstResponse = response.getResponses()[0]; //第一次搜索 assertNull(firstResponse.getFailure()); // 它执行成功了，所以getFailure返回null。 SearchResponse searchResponse = firstResponse.getResponse();//getResponse中有一个searchResponse。 assertEquals(4, searchResponse.getHits().getTotalHits().value); MultiSearchResponse.Item secondResponse = response.getResponses()[1];//第二次搜索 assertNull(secondResponse.getFailure()); searchResponse = secondResponse.getResponse(); assertEquals(1, searchResponse.getHits().getTotalHits().value); "}}